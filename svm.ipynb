{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "#approxximating\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import sklearn.svm as svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from category_encoders import *\n",
    "\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn import tree\n",
    "from math import trunc\n",
    "from math import ceil\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from c45 import C45\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "#from tabulate import tabulate\n",
    "\n",
    "#sklearnex\n",
    "#import sys\n",
    "#sys.path.insert(0, \"C:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearnex\")\n",
    "#import \n",
    "#import daal4py.sklearn\n",
    "\n",
    "\n",
    "#regex\n",
    "import re\n",
    "\n",
    "#This is for optimization\n",
    "\n",
    "#For randomness:\n",
    "import random\n",
    "\n",
    "#For different classifiers:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel=\"linear\", C=1)\n",
    "clf2= svm.SVC(kernel=\"linear\", C=1)\n",
    "pipe = make_pipeline(StandardScaler(),clf)\n",
    "X = np.array([[-1, -1], [-2, -1],[-3,-1],[3,1], [1, 1], [2, 1],[2.5,1],[1.5,1]])\n",
    "Z = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "A = np.array([1, 1, 2,2])\n",
    "Y = np.array([1, 1, 2, 1, 2, 1,2,2])\n",
    "clf.fit(X,Y)\n",
    "clf2.fit(Z,A)\n",
    "R=np.array_split(X,3)\n",
    "#print(R)\n",
    "#ARF load, py.io\n",
    "# Target, and ordinal is good.\n",
    "# anaconda and jupyter notebook\n",
    "\n",
    "# svm.Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "#                 ('svc', SVC(gamma='auto'))])\n",
    "\n",
    "#print(clf.predict([[-.8,-1]]))\n",
    "vecotr= clf.support_vectors_\n",
    "vecotr2= clf2.support_vectors_\n",
    "#print(clf.decision_function(vecotr))\n",
    "#print(clf2.decision_function(vecotr2))\n",
    "marginDensity= 0\n",
    "\n",
    "\n",
    "#polymorphism vs the abstract factory. Make the code well.Why not an abstract factor. cuz drift detector with the thing. needs it.\n",
    "\n",
    "class MDDriftDetector(ABC):\n",
    "\n",
    "    def KXVal(self, data, labels,K,*classifierSettings):\n",
    "        splitData=np.array_split(data,K)\n",
    "        splitLabels=np.array_split(labels,K)\n",
    "        accuracies = np.zeros(K)\n",
    "        densities = np.zeros(K)\n",
    "        for i in range(K):\n",
    "            trainData = np.concatenate(splitData[:i]+splitData[i+1:])\n",
    "            trainLabels= np.concatenate(splitLabels[:i]+splitLabels[i+1:])\n",
    "            dens,acc= self.CrossValid(trainData,splitData[i],trainLabels,splitLabels[i],classifierSettings)\n",
    "            accuracies[i]= acc\n",
    "            densities[i] = dens\n",
    "        averageAccuracy= np.average(accuracies)\n",
    "        standardDevAccuracy= np.std(accuracies)\n",
    "        averageDensity=np.average(densities)\n",
    "        standardDevDensity=np.std(densities)\n",
    "        return averageAccuracy, standardDevAccuracy,averageDensity,standardDevDensity\n",
    "\n",
    "    def CrossValid(self,trainData,testData,trainLabels,testLabels, classifierSettings):\n",
    "        classifier= self.trainClassifier(trainData,trainLabels,classifierSettings)\n",
    "        density = self.findMarginDensity(trainData,classifier)\n",
    "        score= classifier.score(testData,testLabels)\n",
    "        #print(score)\n",
    "        return density, score\n",
    "\n",
    "        #checks if drift occurs\n",
    "    def checkDriftAccuracy(self,batch,labels):\n",
    "        if batch.size==labels.size:\n",
    "            score=self.classifier.score(batch,labels)\n",
    "            if self.avAc-score>self.stdDensThresh*self.stdAc:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        #detects the MD3 drift\n",
    "    def calculateMD3drift(self,batch):\n",
    "        batchMD= self.findMarginDensity(batch,self.classifier)\n",
    "        #print(\"this is selfdensity\" + str(self.density))\n",
    "        #print(\"this is batchDensity\" + str(batchMD))\n",
    "        #print(\"this is selfstandardDeviation\"+ str(self.stdDens))\n",
    "        if np.abs(batchMD-self.density)>self.stdDensThresh*self.stdDens:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def calculateAccuracy(self,data,labels):\n",
    "        score = self.classifier.score(data,labels)\n",
    "        #print(\"this is accuracy\"+ str(score))\n",
    "        return score\n",
    "    \n",
    "    @abstractmethod\n",
    "    def trainClassifier(self,trainData,trainLabels,classifierSettings):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def findMarginDensity(self,classifier,trainData):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def train(self,trainData,trainLabels):\n",
    "        pass\n",
    "    # @abstractmethod\n",
    "    # def detectDrift(self,batch):\n",
    "    #     pass\n",
    "\n",
    "#initiializes drift detector\n",
    "#python allows no arguement overloading.\n",
    "class DriftDetector(MDDriftDetector):\n",
    "    def __init__(self, kernel,C,K,toobig=False):\n",
    "        \n",
    "\n",
    "        self.kernel=kernel\n",
    "        self.C=C\n",
    "        self.K=K\n",
    "        self.avAc=None\n",
    "        self.stdAc=None\n",
    "        self.stdDens=None\n",
    "        self.classifier=None\n",
    "        self.density = None\n",
    "        self.stdDensThresh=2\n",
    "        #The ones needed for md3:1\n",
    "        self.max=self.density\n",
    "        self.min=self.density\n",
    "        self.thresh= None\n",
    "\n",
    "        self.toobig=toobig\n",
    "        \n",
    "#needs to be adapted for window stuff.\n",
    "    def findMarginDensity(self,batch,svm):\n",
    "        marginDensity=0\n",
    "        for vect in batch:\n",
    "            if np.abs(svm.decision_function([vect]))<=1:\n",
    "                marginDensity= marginDensity+1\n",
    "        return marginDensity/batch.size\n",
    "    \n",
    "    #creates a new classifier then fit it. Return that new Classifier\n",
    "    #could use wargs for key value pair.\n",
    "\n",
    "    def trainClassifier(self,data,labels, classifierSettings):\n",
    "        clf=None\n",
    "        if self.toobig==True:\n",
    "            clf = svm.LinearSVC()\n",
    "            feature_map_nystroem = Nystroem(gamma=.2,\n",
    "                                random_state=1,\n",
    "                                n_components=300)\n",
    "            data_transformed = feature_map_nystroem.fit_transform(data)\n",
    "        else:\n",
    "            clf= svm.SVC(kernel=classifierSettings[0],C=classifierSettings[1])\n",
    "        clf.fit(data,labels)\n",
    "        return clf\n",
    "\n",
    "    #multiclass? linear? etc. retrain once found problem.\n",
    "    def retrain(self,data,labels,kernel,C,K):\n",
    "        self.classifier.fit(data,labels)\n",
    "        density = self.findMarginDensity(data)\n",
    "        self.max=density\n",
    "        self.min=density\n",
    "        avAc,stdAc,stdDens= self.KXVal(data,labels,kernel,C,K)\n",
    "        self.density=density\n",
    "        self.avAc=avAc\n",
    "        self.stdAc=stdAc\n",
    "        self.stdDens=stdDens\n",
    "    \n",
    "    def train(self,data,labels):\n",
    "        #If we pass stuff yea.\n",
    "        avAc,stdAc,avDens,stdDens= self.KXVal(data,labels,self.K,self.kernel,self.C)\n",
    "        self.avAc=avAc\n",
    "        self.stdAc=stdAc\n",
    "        self.stdDens=stdDens\n",
    "        classifier= self.trainClassifier(data,labels,(self.kernel,self.C))\n",
    "        self.classifier= classifier\n",
    "        self.density = avDens\n",
    "        self.stdDensThresh=3\n",
    "##cross avlidaton, gets the distribution components.\n",
    "    \n",
    "\n",
    "class MD3V1(MDDriftDetector):\n",
    "    def __init__(self,kernel,C,threshold,toobig=False):\n",
    "        classifier= None\n",
    "        self.kernel=kernel\n",
    "        self.C=C\n",
    "        self.max=None\n",
    "        self.min=None\n",
    "        self.threshold = threshold\n",
    "        self.thresh= None\n",
    "        self.toobig=toobig\n",
    "        \n",
    "    def findMarginDensity(self,batch,svm):\n",
    "        marginDensity=0\n",
    "        for vect in batch:\n",
    "            if np.abs(svm.decision_function([vect]))<=1:\n",
    "                marginDensity= marginDensity+1\n",
    "        return marginDensity/batch.size\n",
    "    \n",
    "    def trainClassifier(self,data,labels, classifierSettings):\n",
    "        if self.toobig==True:\n",
    "            clf= svm.LinearSVC(C=self.C)\n",
    "            feature_map_nystroem = Nystroem(gamma=.2,\n",
    "                                random_state=1,\n",
    "                                n_components=300)\n",
    "            data_transformed = feature_map_nystroem.fit_transform(data)\n",
    "        else:\n",
    "            clf= svm.SVC(kernel=self.kernel,C=self.C)\n",
    "        clf.fit(data,labels)\n",
    "        return clf\n",
    "    \n",
    "    def train(self,data,labels):\n",
    "        classifier= self.trainClassifier(data,labels,(self.kernel,self.C))\n",
    "        self.classifier=classifier\n",
    "        density=self.findMarginDensity(data,classifier)\n",
    "        self.density=density\n",
    "        self.max= density\n",
    "        self.min= density\n",
    "        self.thresh= self.density * self.threshold\n",
    "\n",
    "        #threshold=0.075\n",
    "\n",
    "    #1st version md3\n",
    "    def calculateMD3drift(self,batch):\n",
    "        md2=self.findMarginDensity(batch,self.classifier)\n",
    "        #print(md2)\n",
    "        if md2>self.max:\n",
    "            self.max=md2\n",
    "        if md2<self.min:\n",
    "            self.min= md2\n",
    "        if (self.max-self.min)>self.thresh:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "\n",
    "\n",
    "\n",
    "#this is for batch, not sliding window. sliding window forgetting factor sus\n",
    "#here supposed to query an oracle callback function.\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "    # very inefficient, right now, creates new svm. need change the svm, so need to use class svm and fit.\n",
    "    \n",
    "\n",
    "class EnsembleMDDriftDetector(MDDriftDetector):\n",
    "        \n",
    "    def __init__(self,K,estimator,numberOf,subspaces,bagging):\n",
    "        #scikit learn parameters\n",
    "        self.K=K\n",
    "        self.estimator=estimator\n",
    "        self.numberOf=numberOf\n",
    "        self.subspaces=subspaces\n",
    "        self.bagging=bagging\n",
    "        #nona ble\n",
    "        self.avAc=None\n",
    "        self.stdAc=None\n",
    "        self.stdDens=None\n",
    "        self.classifier = None\n",
    "        self.density= None\n",
    "        self.stdDensThresh=3\n",
    "\n",
    "\n",
    "    def trainClassifier(self,data,labels,classifierSettings):\n",
    "        bagging = BaggingClassifier(classifierSettings[0],n_estimators=classifierSettings[1],max_samples=float(1)\n",
    "        ,max_features=classifierSettings[2],bootstrap= classifierSettings[3],n_jobs=1)\n",
    "        bagging.fit(data,labels)\n",
    "        return bagging\n",
    "\n",
    "\n",
    "    def findMarginDensity(self,batch,classifier):\n",
    "        marginDensity=0\n",
    "        probabilitiesEach= classifier.predict_proba(batch)\n",
    "        for vect in probabilitiesEach:\n",
    "            if np.abs(vect[0]-(1-vect[0]))<.5:\n",
    "                print(np.abs(vect[0]-(1-vect[0])))\n",
    "                marginDensity= marginDensity+1\n",
    "        return marginDensity/batch.size\n",
    "    \n",
    "    def train(self,data,labels):\n",
    "        avAc,stdAc,avDens,stdDens= self.KXVal(data,labels,self.K,self.estimator,self.numberOf,self.subspaces,self.bagging)\n",
    "        self.avAc=avAc\n",
    "        self.stdAc=stdAc\n",
    "        self.stdDens=stdDens\n",
    "        self.classifier = self.trainClassifier(data,labels,(self.estimator,self.numberOf,self.subspaces,self.bagging))\n",
    "        self.density= avDens\n",
    "        self.stdDensThresh=2\n",
    "        \n",
    "\n",
    "\n",
    "class FuzzyDetector(EnsembleMDDriftDetector):\n",
    "    \n",
    "    def membershipFun(self,x):\n",
    "        membership=0\n",
    "        confidence = np.abs(x-(1-x))\n",
    "        if confidence <= .5:\n",
    "             membership = (np.cos(np.pi*confidence)+1)/2\n",
    "        return membership\n",
    "\n",
    "    def findMarginDensity(self,batch,classifier):\n",
    "        probabilitiesEach = classifier.predict_proba(batch)\n",
    "        fmd=0\n",
    "        for vect in probabilitiesEach:\n",
    "            membership = self.membershipFun(vect[0])\n",
    "            fmd=fmd+ membership\n",
    "        return fmd/batch.size\n",
    "\n",
    "\n",
    "    \n",
    "dd= DriftDetector(\"linear\",1,2)\n",
    "dd.train(X,Y)\n",
    "if dd.calculateMD3drift(X):\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")\n",
    "\n",
    "def createBestKNNDetector(data,labels,maxK):\n",
    "    k_range = range(4, maxK)\n",
    "\n",
    "    k_scores = np.zeros(maxK)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size=0.30, shuffle=False)\n",
    "\n",
    "\n",
    "    for k in k_range:\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        k_scores[k]= cross_val_score(model, data, labels, cv=10).mean()\n",
    "        #print(k_scores[k])\n",
    "\n",
    "    optimizedNeighbors= k_scores.argmax()\n",
    "    print(\"optimized neighbors for this is: \" + str(optimizedNeighbors))\n",
    "    return KNeighborsClassifier(n_neighbors=optimizedNeighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from category_encoders import TargetEncoder\n",
    "\n",
    "\n",
    "realWorldSources= np.array([\n",
    "    \"electricity_dataset.csv\",\n",
    "    \"weather_dataset.csv\",\n",
    "    \"airline_dataset.csv\",\n",
    "    \"spam_dataset.csv\"])\n",
    "#preprocessing.\n",
    "#LabelEncoder\n",
    "#iloc and sclice...\n",
    "#functions to help make arf to usable data\n",
    "def getCatColumns(pandaFrame):\n",
    "    names = pandaFrame.select_dtypes(exclude=np.number).columns.tolist()\n",
    "    return names\n",
    "    \n",
    "    #very inefficient, find way to get the last part and see if case, and match \n",
    "    #this is there to check what type of file it is and return a pandas frame.\n",
    "def dfFromUnknownType(link):\n",
    "    x = re.findall(\"arff$\", link)\n",
    "\n",
    "    if x:\n",
    "        data = arff.loadarff(link)[0]\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        x = re.findall(\"csv$\",link)\n",
    "        if x:\n",
    "            return pd.read_csv(link)\n",
    "        else:\n",
    "            print(\"not a valid File Type, change code or filetype\")\n",
    "\n",
    "def divideIntoBatchesOfX(array,X):\n",
    "    if array.ndim>1:\n",
    "        return np.array_split(array,ceil(array.shape[0]/X))\n",
    "    else:\n",
    "        return np.array_split(array,ceil(array.size/X))\n",
    "\n",
    "def getTrainSet(link,data,labels):\n",
    "    if link== \"electricity_dataset.csv\":\n",
    "            A=np.delete(data[:15104],np.array([0,1,7]),1)\n",
    "            return A,labels[:15104]\n",
    "            #divideIntoBatchesOfX(data[:15104],365), divideIntoBatchesOfX(labels[:15104],365)\n",
    "    elif link==\"weather_dataset.csv\":\n",
    "        return data[:6053],labels[:6053]\n",
    "\n",
    "\n",
    "    elif link==\"airline_dataset.csv\":\n",
    "        return data[:179794],labels[:179794]\n",
    "\n",
    "\n",
    "    else:\n",
    "        return data[:1468],labels[:1468]\n",
    "\n",
    "\n",
    "\n",
    "def getTestBatches(link, data, labels):\n",
    "    if link== \"electricity_dataset.csv\":\n",
    "        A=np.delete(data[-30208:],np.array([0,1,7]),1)\n",
    "        return A, labels[-30208:]\n",
    "        \n",
    "    elif link==\"weather_dataset.csv\":\n",
    "        return data[-12106:],labels[-12106:]\n",
    "\n",
    "    elif link==\"airline_dataset.csv\":\n",
    "        return data[-359589:],labels[-359589:]\n",
    "\n",
    "    else:\n",
    "        return data[-2937:],labels[-2937:]\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def fromFiletoData(link,className,encoder):\n",
    "    df= dfFromUnknownType(link)\n",
    "    #encode labels\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels= le.fit_transform(df[[className]].values.ravel())\n",
    "    df=df.drop(columns=[className],axis=1)\n",
    "    print(\"preprocessed\",flush=True)\n",
    "    #encode categorical\n",
    "    columns = getCatColumns(df)\n",
    "    if encoder==\"Ordinal\":\n",
    "        ord= preprocessing.OrdinalEncoder()\n",
    "        df[columns[:]]=ord.fit_transform(df[columns[:]])\n",
    "    elif \"OH\": \n",
    "        df= pd.get_dummies(df)\n",
    "\n",
    "    elif \"Target\":\n",
    "        te = TargetEncoder(cols=columns, smoothing=0, return_df=False)\n",
    "\n",
    "    #df = te.fit_transform(df, labels)\n",
    "    scaler= MinMaxScaler()\n",
    "    print(\"get the preprocessed things\",flush=True)\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    #df= scaler.fit_transform(df)\n",
    "    print(df,flush=True)\n",
    "    if not encoder==\"Target\":\n",
    "        df=df.to_numpy()\n",
    "    print(\"tonumpy.\",flush=True)\n",
    "    return df , labels\n",
    "\n",
    "# link = \"agraw1_1_abrupt_drift_0_noise_balanced.arff\"\n",
    "# data,labels = fromArftoData(\"agraw1_1_abrupt_drift_0_noise_balanced.arff\")\n",
    "# drifDet= DriftDetector(data[:30000],labels[:30000],\"linear\",1,10)\n",
    "#print(data)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Real World Drift\n",
    "\n",
    "realWorldSources= np.array([\n",
    "    \"electricity_dataset.csv\",\n",
    "    \"weather_dataset.csv\",\n",
    "    \"airline_dataset.csv\",\n",
    "    \"spam_dataset.csv\"])\n",
    "\n",
    "# as the ammount of data goes to infinity, it will describe the thing the best. so the standard deviation will be... \n",
    "# statisticall, sampling a statistic stdDev\n",
    "#This if for the drift calculations\n",
    "\n",
    "def getClassifierAccuracy(link,data,labels,classifier):\n",
    "    numberOfCrossValidations= 40\n",
    "    trainBatches, totalTrainLabels = getTrainSet(link,data,labels)\n",
    "    divBatch=divideIntoBatchesOfX(trainBatches,365)\n",
    "    divLabels=divideIntoBatchesOfX(totalTrainLabels,365)\n",
    "    accuracies = np.zeros(numberOfCrossValidations)\n",
    "    for i in range(numberOfCrossValidations):\n",
    "        rand=random.randint(0,len(divBatch)-1)\n",
    "        trainData = np.concatenate(divBatch[:rand] + divBatch[rand+1:])\n",
    "        trainLabels= np.concatenate(divLabels[:rand] + divLabels[rand+1:])\n",
    "        classifier.fit(trainData,trainLabels)\n",
    "        accuracies[i]=classifier.score(divBatch[rand],divLabels[rand])\n",
    "    averageAccuracy= np.average(accuracies)\n",
    "    standardDevAccuracy= np.std(accuracies)\n",
    "    return averageAccuracy,standardDevAccuracy\n",
    "\n",
    "## This way to find Real World drift is deprecated, see common repository.\n",
    "\n",
    "#Outputs graph of each batch accuracy for each classifier\n",
    "# def findRealWorldDrift(theSources):\n",
    "    \n",
    "#     ##this is getting the accuracies\n",
    "#     for ind in range(theSources.size):\n",
    "#         data,labels = fromFiletoData(theSources[ind])\n",
    "#         trainBatch,trainLabels= getTrainSet(theSources[ind],data,labels)\n",
    "#                 ##classifiers to try stuff out.\n",
    "        \n",
    "#         classifiers =np.array( [\n",
    "#         createBestKNNDetector(trainBatch,trainLabels,50),\n",
    "#         svm.SVC(kernel=\"linear\", C=1),\n",
    "#         svm.SVC(kernel=\"poly\", C=1),\n",
    "#         svm.SVC(gamma=2, C=1),\n",
    "#         #GaussianProcessClassifier(1.0 * RBF(1.0),  n_jobs = -1),\n",
    "#         DecisionTreeClassifier(max_depth=8),\n",
    "#         RandomForestClassifier(max_depth=8, n_estimators=11, max_features=2),\n",
    "#         MLPClassifier(alpha=1, max_iter=1000),\n",
    "#         AdaBoostClassifier(),\n",
    "#         GaussianNB(),\n",
    "#         QuadraticDiscriminantAnalysis(),\n",
    "#             ])\n",
    "#         ############\n",
    "#         accuracies= np.zeros(classifiers.size)\n",
    "#         deviations= np.zeros(classifiers.size)\n",
    "#         ###finding expected accuracy and deviation, and fitting\n",
    "#         for classi in range(classifiers.size):\n",
    "#             accuracies[classi],deviations[classi] = getClassifierAccuracy(theSources[ind],data,labels,classifiers[classi])\n",
    "#             classifiers[classi].fit(trainBatch,trainLabels)\n",
    "            \n",
    "#         ##This is finding when accuracies deviate\n",
    "#             testBatch,labelBatch= getTestBatches(theSources[ind],data,labels)\n",
    "#             batchAccuracies=np.zeros(ceil(len(testBatch)))\n",
    "#             drifts= np.zeros(len(testBatch))\n",
    "#             for batchNum in range(ceil(len(testBatch))):\n",
    "#                 batchAccuracy = classifiers[classi].score(testBatch[batchNum],labelBatch[batchNum])\n",
    "#                 batchAccuracies[batchNum]=batchAccuracy\n",
    "#                 if accuracies[classi]-1*deviations[classi] > batchAccuracy:\n",
    "#                     drifts[batchNum]=True\n",
    "\n",
    "#             print(drifts)\n",
    "#             path = str(classi) + \"path.csv\"\n",
    "#             pd.DataFrame(drifts).to_csv(path)\n",
    "#             print(accuracies[classi])\n",
    "#             print(deviations[classi])\n",
    "#             plt.bar(np.arange(0,len(testBatch)),batchAccuracies)\n",
    "#             plt.axhline(accuracies[classi]-1*deviations[classi])\n",
    "#             plt.show()\n",
    "    \n",
    "# findRealWorldDrift(realWorldSources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post processing functions\n",
    "\n",
    "#Metrics:\n",
    "\n",
    "def getFalsePositive(detections,batchNumber):\n",
    "    print(detections)\n",
    "    falsePositives=0\n",
    "    for i in range(batchNumber-1):\n",
    "        if(detections[i]):\n",
    "            falsePositives = falsePositives+1\n",
    "    return falsePositives/(batchNumber-1)\n",
    "\n",
    "\n",
    "def getLatency(detections,batchNumber):\n",
    "    latency=0\n",
    "    for i in range(batchNumber,detections.size):\n",
    "        if(not detections[i]):\n",
    "            latency= latency +1\n",
    "        else:\n",
    "            break\n",
    "    return latency/(detections.size-batchNumber)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Nice plot Graphs\n",
    "def plotNiceLineGraph(data,title,titleX,titleY,labelData):\n",
    "    if len(data)>1:\n",
    "        for ind in range(len(data)):\n",
    "            plt.plot(data[ind],label = labelData[ind])\n",
    "    else:\n",
    "        plt.plot(data[0])\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(titleX, fontsize=15)\n",
    "    plt.ylabel(titleY, fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "#Bar graph\n",
    "def plotNiceBarGraph(content,title):\n",
    "    df = pd.DataFrame(content)\n",
    "    df.plot(kind='bar',title = title)\n",
    "\n",
    "#Not \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making nice Tables\n",
    "\n",
    "def tableToLatex(content,columNames,rowNames,fileToSave):\n",
    "    df = pd.DataFrame(content, columNames, rowNames)\n",
    "    print(df)\n",
    "    string = df.to_latex()\n",
    "    print(string)\n",
    "    text_file = open(fileToSave, \"wt\")\n",
    "    n = text_file.write(string)\n",
    "    text_file.close()\n",
    "\n",
    "def tableToExcel(content,columNames,rowNames,fileToSave):\n",
    "    df = pd.DataFrame(content, columNames, rowNames)\n",
    "    df.to_excel(fileToSave)\n",
    "    # print(df)\n",
    "    # string = df.to_latex()\n",
    "    # print(string)\n",
    "    # text_file = open(fileToSave, \"wt\")\n",
    "    # n = text_file.write(string)\n",
    "    # text_file.close()\n",
    "\n",
    "#tableToLatex(np.array([[.5,22,33],[44,55,66]]),np.array([\"a\",\"b\"]),np.array([\"col1\",\"col2\",\"col3\"]),\"test.txt\")\n",
    "\n",
    "#To Latex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Metrics:\n",
    "\n",
    "def getFalsePositive(detections,batchNumber):\n",
    "    print(detections)\n",
    "    falsePositives=0\n",
    "    for i in range(batchNumber-1):\n",
    "        if(detections[i]):\n",
    "            falsePositives = falsePositives+1\n",
    "    return falsePositives/(batchNumber-1)\n",
    "\n",
    "\n",
    "def getLatency(detections,batchNumber):\n",
    "    latency=0\n",
    "    for i in range(batchNumber,detections.size):\n",
    "        if(not detections[i]):\n",
    "            latency= latency +1\n",
    "        else:\n",
    "            break\n",
    "    return latency/(detections.size-batchNumber)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "get the preprocessed things\n",
      "        attrib1   attrib2   attrib3\n",
      "0      0.730893  0.410086  0.207707\n",
      "1      0.583365  0.042295  0.761678\n",
      "2      0.139764  0.694960  0.805231\n",
      "3      0.275034  0.075385  0.610591\n",
      "4      0.204916  0.623374  0.184699\n",
      "...         ...       ...       ...\n",
      "99995  0.463652  0.663948  0.006662\n",
      "99996  0.425207  0.335127  0.565219\n",
      "99997  0.413148  0.637183  0.312550\n",
      "99998  0.140423  0.439256  0.929862\n",
      "99999  0.723190  0.877063  0.392545\n",
      "\n",
      "[100000 rows x 3 columns]\n",
      "tonumpy.\n",
      "next detector\n",
      "next detector\n",
      "Source:sea_1_abrupt_drift_0_noise_balanced.arff\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 108\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[39mprint\u001b[39m(latencies[x][ind])\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m(fprs,latencies)\n\u001b[1;32m--> 108\u001b[0m fpr,latency\u001b[39m=\u001b[39m testOnSynthetic(syntheticSources,\u001b[39m4\u001b[39;49m,[\u001b[39m\"\u001b[39;49m\u001b[39mMD3V2\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mMD3_Tree\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mFuzzy_Tree\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    109\u001b[0m \u001b[39mprint\u001b[39m(fpr,latency)\n\u001b[0;32m    110\u001b[0m \u001b[39m#tableToLatex(fpr,detectorNames,sourceNames,\"fprRealWorld.txt\")\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# plotNiceBarGraph(fpr,sourceNames,detectorNames,\"False Positive Rate Synthetic\")\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m# plotNiceBarGraph(latency,sourceNames,detectorNames,\"Latency Synthetic\")\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m##to change perhaps: expected density etc.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 92\u001b[0m, in \u001b[0;36mtestOnSynthetic\u001b[1;34m(theSources, detectorNum, detectorNames)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(detectors\u001b[39m.\u001b[39msize):\n\u001b[0;32m     91\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(testBatches)):\n\u001b[1;32m---> 92\u001b[0m         detections[x][i] \u001b[39m=\u001b[39mdetectors[x]\u001b[39m.\u001b[39;49mcalculateMD3drift(testBatches[i])\n\u001b[0;32m     93\u001b[0m     \u001b[39m#     marginDensities[x][i] = detectors[x].findMarginDensity(testBatches[i],detectors[x].classifier)\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[39m#     accuracies[x][i] = detectors[x].calculateAccuracy(testBatches[i],testlabels[i])\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[39m# print(detectors[x].density,detectors[x].stdDens,flush=True)\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[39m# plotNiceLineGraph([accuracies[x, :]],detectorNames[x],\"Batch\",\"percentage\",[\"Accuracy\"])\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[39m# plotNiceLineGraph([marginDensities[x, :]],detectorNames[x],\"Batch\",\"percentage\",[\"Margin Density\"])\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(detectors\u001b[39m.\u001b[39msize):\n",
      "Cell \u001b[1;32mIn[11], line 206\u001b[0m, in \u001b[0;36mMD3V1.calculateMD3drift\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculateMD3drift\u001b[39m(\u001b[39mself\u001b[39m,batch):\n\u001b[1;32m--> 206\u001b[0m     md2\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfindMarginDensity(batch,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier)\n\u001b[0;32m    207\u001b[0m     \u001b[39m#print(md2)\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m md2\u001b[39m>\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax:\n",
      "Cell \u001b[1;32mIn[11], line 177\u001b[0m, in \u001b[0;36mMD3V1.findMarginDensity\u001b[1;34m(self, batch, svm)\u001b[0m\n\u001b[0;32m    175\u001b[0m marginDensity\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[39mfor\u001b[39;00m vect \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mabs(svm\u001b[39m.\u001b[39;49mdecision_function([vect]))\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    178\u001b[0m         marginDensity\u001b[39m=\u001b[39m marginDensity\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m marginDensity\u001b[39m/\u001b[39mbatch\u001b[39m.\u001b[39msize\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearnex\\_device_offload.py:181\u001b[0m, in \u001b[0;36mwrap_output_data.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     usm_iface \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(data[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m__sycl_usm_array_interface__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 181\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m usm_iface \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m _copy_to_usm(usm_iface[\u001b[39m'\u001b[39m\u001b[39msyclobj\u001b[39m\u001b[39m'\u001b[39m], result)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearnex\\svm\\svc.py:161\u001b[0m, in \u001b[0;36mSVC.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m Version(sklearn_version) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 161\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(\u001b[39mself\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msvm.SVC.decision_function\u001b[39;49m\u001b[39m'\u001b[39;49m, {\n\u001b[0;32m    162\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39monedal\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m_onedal_decision_function,\n\u001b[0;32m    163\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39msklearn\u001b[39;49m\u001b[39m'\u001b[39;49m: sklearn_SVC\u001b[39m.\u001b[39;49mdecision_function,\n\u001b[0;32m    164\u001b[0m }, X)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearnex\\_device_offload.py:158\u001b[0m, in \u001b[0;36mdispatch\u001b[1;34m(obj, method_name, branches, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msklearn.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mget_patch_message(backend,\u001b[39m \u001b[39mq,\u001b[39m \u001b[39mcpu_fallback)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39monedal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m branches[backend](obj, \u001b[39m*\u001b[39mhostargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhostkwargs, queue\u001b[39m=\u001b[39mq)\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msklearn\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m branches[backend](obj, \u001b[39m*\u001b[39mhostargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhostkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearnex\\svm\\svc.py:234\u001b[0m, in \u001b[0;36mSVC._onedal_decision_function\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_onedal_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X, queue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_onedal_estimator\u001b[39m.\u001b[39;49mdecision_function(X, queue\u001b[39m=\u001b[39;49mqueue)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\onedal\\svm\\svm.py:406\u001b[0m, in \u001b[0;36mSVC.decision_function\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X, queue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_decision_function(X, _backend\u001b[39m.\u001b[39;49msvm\u001b[39m.\u001b[39;49mclassification, queue)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\onedal\\svm\\svm.py:308\u001b[0m, in \u001b[0;36mBaseSVM._decision_function\u001b[1;34m(self, X, module, queue)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X, module, queue):\n\u001b[0;32m    307\u001b[0m     _check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 308\u001b[0m     X \u001b[39m=\u001b[39m _check_array(X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m    309\u001b[0m                      force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    310\u001b[0m     _check_n_features(\u001b[39mself\u001b[39m, X, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    312\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\onedal\\datatypes\\validation.py:105\u001b[0m, in \u001b[0;36m_check_array\u001b[1;34m(array, dtype, accept_sparse, order, copy, force_all_finite, ensure_2d, accept_large_sparse)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_array\u001b[39m(array, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m, accept_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    101\u001b[0m                  copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m                  ensure_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    103\u001b[0m     \u001b[39m# TODO\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m check_array\n\u001b[1;32m--> 105\u001b[0m     array \u001b[39m=\u001b[39m check_array(array\u001b[39m=\u001b[39;49marray, dtype\u001b[39m=\u001b[39;49mdtype, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    106\u001b[0m                         order\u001b[39m=\u001b[39;49morder, copy\u001b[39m=\u001b[39;49mcopy, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    107\u001b[0m                         ensure_2d\u001b[39m=\u001b[39;49mensure_2d, accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse)\n\u001b[0;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(array):\n\u001b[0;32m    110\u001b[0m         \u001b[39mreturn\u001b[39;00m array\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\"sea_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "syntheticSources = np.array([\n",
    "    \"sea_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "    \"agraw1_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "\"agraw2_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_20.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_20.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_20.arff\"])\n",
    "\n",
    "sourceNames=[\"sea A\",\"agraw1 A\",\"agraw2 A\",\"agraw1_05\",\"agraw1_1\",\"agraw1_5\",\n",
    "\"agraw1_10\",\"agraw1_20\",\"agraw2_05\",\"agraw2_1\",\"agraw2_5\",\"agraw2_10\",\"agraw2_20\",\n",
    "\"sea_05\",\"sea_1\",\"sea_5\",\"sea_10\",\"sea_20\"]\n",
    "\n",
    "detectorNames=[\"MD3V1\",\"MD3V2\",\"MD3_Tree\",\"Fuzzy_Tree\"]\n",
    "\n",
    "# for ind in range(2,theSources.size):\n",
    "#     data,labels = fromArftoData(theSources[ind])\n",
    "#     #print(data)\n",
    "#     drifDet= DriftDetector(data[:30000],labels[:30000],\"poly\",1,5)\n",
    "#     print(\"This is the average accuracy of this model:\"+str(drifDet.avAc),flush=True)\n",
    "#     batches = np.array_split(data,10)\n",
    "#     batches = np.asarray(batches)\n",
    "#     print(\"Source:\" + theSources[ind])\n",
    "#     for i in range(3,batches.shape[0]):\n",
    "#         if drifDet.calculateMD3drift(batches[i]):\n",
    "#             print(\"yes\")\n",
    "#         else:\n",
    "#             print(\"no\")\n",
    "\n",
    "#using target instead.\n",
    "\n",
    "#BaggingClassifier(estimator= kwargs[0],n_estimators=kwargs[1],max_samples=float(1),max_features=kwargs[2],bootstrap= kwargs[3],n_jobs=-1)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testOnSource(source,detectors):\n",
    "    data, labels = fromFiletoData(source)\n",
    "    latencies= np.zeros(detectors.size)\n",
    "    fprs= np.zeros(detectors.size)\n",
    "\n",
    "    \n",
    "#5,etc,...\n",
    "#will give false positive rates, and will plot \n",
    "def testOnSynthetic(theSources,detectorNum,detectorNames):\n",
    "    #data of table.\n",
    "    fprs=np.zeros(shape=(detectorNum, theSources.size))\n",
    "    latencies=np.zeros(shape=(detectorNum, theSources.size))\n",
    "    \n",
    "    for ind in range(theSources.size):\n",
    "        data,labels = fromFiletoData(theSources[ind],\"class\",\"Ordinal\")\n",
    "        trainData = data[:30000]\n",
    "        trainLabels= labels[:30000]\n",
    "        \n",
    "        #this is there to make the detectors KN crashes for me. internal error.\n",
    "        md3V1 = MD3V1(\"linear\",1,.05)\n",
    "        drifDet= DriftDetector(\"linear\",1,5)\n",
    "        # ensembleTreeDetector = EnsembleMDDriftDetector(5,tree.DecisionTreeClassifier(),20,trunc(data.shape[1]/2),False) #needs to be changed...\n",
    "        # knEnsemble= EnsembleMDDriftDetector(5,KNeighborsClassifier(33),20,trunc(data.shape[1]/2),False)\n",
    "        # fuzzyTree = FuzzyDetector(5,tree.DecisionTreeClassifier(),20,trunc(data.shape[1]/2),False)\n",
    "        # fuzzyKn = FuzzyDetector(5,KNeighborsClassifier(33),20,trunc(data.shape[1]/2),False)\n",
    "\n",
    "        testBatches = divideIntoBatchesOfX(data[-70000:],10000)\n",
    "        testlabels = divideIntoBatchesOfX(labels[-70000:],10000)\n",
    "        \n",
    "        detectors = np.array([md3V1,drifDet])\n",
    "        for detector in detectors:\n",
    "            print(\"next detector\", flush=True)\n",
    "            detector.train(trainData,trainLabels)\n",
    "\n",
    "        detections = np.zeros(shape=(detectors.size, len(testBatches)))\n",
    "        marginDensities = np.zeros(shape=(detectors.size, len(testBatches)))\n",
    "        accuracies = np.zeros(shape=(detectors.size, len(testBatches)))\n",
    "\n",
    "        print(\"Source:\" + theSources[ind])\n",
    "        for x in range(detectors.size):\n",
    "            for i in range(len(testBatches)):\n",
    "                detections[x][i] =detectors[x].calculateMD3drift(testBatches[i])\n",
    "                marginDensities[x][i] = detectors[x].findMarginDensity(testBatches[i],detectors[x].classifier)\n",
    "                accuracies[x][i] = detectors[x].calculateAccuracy(testBatches[i],testlabels[i])\n",
    "            print(detectors[x].density,detectors[x].stdDens,flush=True)\n",
    "            plotNiceLineGraph([accuracies[x, :]],detectorNames[x],\"Batch\",\"percentage\",[\"Accuracy\"])\n",
    "            plotNiceLineGraph([marginDensities[x, :]],detectorNames[x],\"Batch\",\"percentage\",[\"Margin Density\"])\n",
    "\n",
    "        for x in range(detectors.size):\n",
    "            fprs[x][ind]= getFalsePositive(detections[x],2)\n",
    "            latencies[x][ind]= getLatency(detections[x],2)\n",
    "            print(fprs[x][ind])\n",
    "            print(latencies[x][ind])\n",
    "    return(fprs,latencies)\n",
    "\n",
    "\n",
    "\n",
    "fpr,latency= testOnSynthetic(syntheticSources,4,[\"MD3V2\",\"MD3_Tree\",\"Fuzzy_Tree\"])\n",
    "print(fpr,latency)\n",
    "#tableToLatex(fpr,detectorNames,sourceNames,\"fprRealWorld.txt\")\n",
    "# plotNiceBarGraph(fpr,sourceNames,detectorNames,\"False Positive Rate Synthetic\")\n",
    "# plotNiceBarGraph(latency,sourceNames,detectorNames,\"Latency Synthetic\")\n",
    "##to change perhaps: expected density etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both 1 etc\n",
    "\n",
    "# [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "#  [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
    "#  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "#  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "# [[1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.2 1. ]\n",
    "#  [1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  0. ]\n",
    "#  [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    "#  [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n",
    "\n",
    "#Did not get better with higher Ns\n",
    "\n",
    "# print(fpr)\n",
    "# print(latency)\n",
    "#metrics are trash need diff ones\n",
    "#RealWorldMetrics\n",
    "def falseAndMiss(detected,real):\n",
    "    drifts = 0\n",
    "    fpr=0\n",
    "    accuracy=0\n",
    "    missed =0\n",
    "    for ind in range(real.size):\n",
    "        if real[ind]==1:\n",
    "            drifts=drifts+1\n",
    "            if (detected[ind]<real[ind]):\n",
    "                missed=missed+1\n",
    "            else:\n",
    "                accuracy=accuracy+1\n",
    "        elif (detected[ind]>real[ind]):\n",
    "            fpr = fpr+1\n",
    "    return fpr/(real.size-drifts),missed/drifts,accuracy/drifts\n",
    "        \n",
    "\n",
    "def findDifference(detected,real):\n",
    "    diff=0\n",
    "    for ind in range(detected.size):\n",
    "        if not detected[ind]==real[ind]:\n",
    "            diff=diff + 1\n",
    "    return diff/detected.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\"sea_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "\n",
    "realWorldDrift =np.array([])\n",
    "\n",
    "sourceNames=[\"sea A\",\"agraw1 A\",\"agraw2 A\",\"agraw1_05\",\"agraw1_1\",\"agraw1_5\",\n",
    "\"agraw1_10\",\"agraw1_20\",\"agraw2_05\",\"agraw2_1\",\"agraw2_5\",\"agraw2_10\",\"agraw2_20\",\n",
    "\"sea_05\",\"sea_1\",\"sea_5\",\"sea_10\",\"sea_20\"]\n",
    "\n",
    "detectorNames=[\"MD3V1\",\"MD3V2\",\"MD3_Tree\",\"MD3KNN\",\"Fuzzy_Tree\",\"FuzzyKNN\"]\n",
    "\n",
    "realWorldSources= np.array([\n",
    "    \"electricity_dataset.csv\",\n",
    "    \"weather_dataset.csv\",\n",
    "    \"airline_dataset.csv\",\n",
    "    \"spam_dataset.csv\"])\n",
    "\n",
    "\n",
    "# for ind in range(2,theSources.size):\n",
    "#     data,labels = fromArftoData(theSources[ind])\n",
    "#     #print(data)\n",
    "#     drifDet= DriftDetector(data[:30000],labels[:30000],\"poly\",1,5)\n",
    "#     print(\"This is the average accuracy of this model:\"+str(drifDet.avAc),flush=True)\n",
    "#     batches = np.array_split(data,10)\n",
    "#     batches = np.asarray(batches)\n",
    "#     print(\"Source:\" + theSources[ind])\n",
    "#     for i in range(3,batches.shape[0]):\n",
    "#         if drifDet.calculateMD3drift(batches[i]):\n",
    "#             print(\"yes\")\n",
    "#         else:\n",
    "#             print(\"no\")\n",
    "\n",
    "#using target instead.\n",
    "\n",
    "#BaggingClassifier(estimator= kwargs[0],n_estimators=kwargs[1],max_samples=float(1),max_features=kwargs[2],bootstrap= kwargs[3],n_jobs=-1)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def realWorld(link,realDrifts,batchSize,className,detectorNames,tooBig=False):\n",
    "\n",
    "    data, labels = fromFiletoData(link,className,\"Ordinal\")\n",
    "    print(\"swag\",flush=True)\n",
    "\n",
    "    trainData,trainLabels = getTrainSet(link,data,labels)\n",
    "\n",
    "    detectors=np.array([\n",
    "   # MD3V1(\"linear\",1,.075,toobig=tooBig), \n",
    "    DriftDetector(\"linear\",1,5,toobig=tooBig),\n",
    "    EnsembleMDDriftDetector(5,tree.DecisionTreeClassifier(),20,trunc(data.shape[1]/2),False),\n",
    "    EnsembleMDDriftDetector(5,createBestKNNDetector(trainData,trainLabels,40),20,trunc(data.shape[1]/2),False),\n",
    "    FuzzyDetector(5,tree.DecisionTreeClassifier(),20,trunc(data.shape[1]/2),False),\n",
    "    FuzzyDetector(5,createBestKNNDetector(trainData,trainLabels,40),20,trunc(data.shape[1]/2),False)\n",
    "    ])\n",
    "    for detector in detectors:\n",
    "            print(\"next detector\", flush=True)\n",
    "            detector.train(trainData,trainLabels)\n",
    "\n",
    "    testData,testLabels = getTestBatches(link,data,labels)\n",
    "    testBatches = divideIntoBatchesOfX(testData,batchSize)\n",
    "    testlabels = divideIntoBatchesOfX(testLabels,batchSize)\n",
    "\n",
    "    print(len(testBatches))\n",
    "    print(realDrifts.size)\n",
    "\n",
    "    detections = np.zeros(shape=(detectors.size, len(testBatches)))\n",
    "    marginDensities = np.zeros(shape=(detectors.size, len(testBatches)))\n",
    "    accuracies = np.zeros(shape=(detectors.size, len(testBatches)))\n",
    "    print(\"Source:\" + link)\n",
    "    fprs= np.zeros(detectors.size)\n",
    "    misseds= np.zeros(detectors.size)\n",
    "    driftAccs= np.zeros(detectors.size)\n",
    "    for x in range(detectors.size):\n",
    "        for i in range(len(testBatches)):\n",
    "            detections[x][i] =detectors[x].calculateMD3drift(testBatches[i])\n",
    "            marginDensities[x][i] = detectors[x].findMarginDensity(testBatches[i],detectors[x].classifier)\n",
    "            accuracies[x][i] = detectors[x].calculateAccuracy(testBatches[i],testlabels[i])\n",
    "        plt.bar(np.arange(0,len(testBatches)),accuracies[x, :])\n",
    "        plt.title(detectorNames[x]+\" Accuracy\")\n",
    "        plt.xlabel(\"Batch\")\n",
    "        plt.axhline(detectors[x].avAc-(detectors[x].stdAc*2))\n",
    "        plt.show()\n",
    "        plt.bar(np.arange(0,len(testBatches)),marginDensities[x, :])\n",
    "        plt.title(detectorNames[x]+\" MD\")\n",
    "        plt.xlabel(\"Batch\")\n",
    "        plt.axhline(detectors[x].density-(detectors[x].stdDens*2))\n",
    "        plt.show()\n",
    "        print(detectors[x].stdDens*2)\n",
    "        fprs[x] , misseds[x] ,driftAccs[x]= falseAndMiss(detections[x, :],realDrifts)\n",
    "\n",
    "    return fprs, misseds,driftAccs\n",
    "    \n",
    "\n",
    "def readDriftToData(fileName):\n",
    "    df= dfFromUnknownType(fileName)\n",
    "    df2 = df.iloc[: , 1:]\n",
    "    myData=df.to_numpy()\n",
    "    mydata=myData.T\n",
    "    onlydata=mydata[1, :]\n",
    "    return onlydata\n",
    "    \n",
    "    \n",
    "    #365 is elec\n",
    "\n",
    "print(readDriftToData(\"ElecDatasetPredict.csv\"))\n",
    "\n",
    "def testElec(detectorNames):\n",
    "    elecDrifts=readDriftToData(\"ElecDatasetPredict.csv\")\n",
    "    fpr,missed,accuracy =realWorld(\"electricity_dataset.csv\",elecDrifts,365,\"label\",detectorNames)\n",
    "    return fpr,missed, accuracy\n",
    "    \n",
    "\n",
    "def testSpam(realDrifts,detectorNames):\n",
    "    batchLengths = [20,50,100]\n",
    "    fprs = []\n",
    "    misseds = []\n",
    "    accuracies = []\n",
    "    for ind in range(len(realDrifts)):\n",
    "        fpr,missed,accuracy = realWorld(\"spam_dataset.csv\",realDrifts[ind],batchLengths[ind],\"ACTUAL_LABEL\",detectorNames)\n",
    "        fprs= fprs + fpr\n",
    "        misseds= misseds + missed\n",
    "        accuracies= accuracies + accuracy\n",
    "    return fprs, misseds,accuracies\n",
    "\n",
    "#All encoders saythe same thing. ordinal is okay.\n",
    "def testAirplane(detectorNames, tooBig=True):\n",
    "    #drifts in batch\n",
    "    realAirplaneDrifts = np.zeros(22)\n",
    "    realAirplaneDrifts[0]=1\n",
    "    fpr,missed,accuracy = realWorld(\"airline_dataset.csv\",realAirplaneDrifts,17000 ,\"Delay\",detectorNames,tooBig=True)\n",
    "    return fpr, missed, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testWeather(detectorNames):\n",
    "    weatherMonthly= np.array([False,False,False,False,False,False,False,False,False,False,True,True,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,True,False,False,True,False,False,False,True,False,False,False,False,False,False,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,False,False,False,True,False,False,False,False,False,False,True,False,False,False,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,False,True,False,True,False,False,False,False,False,False,True,False,False,False,False,False,False,False,True,False,False,False,False,True,False,False,False,False,False,True,True,True,True,True,True,False,False,False,False,True,False,True,True,False,False,False,False,False,True,False,False,False,False,True,False,False,False,False,False,False,False,True,False,False,False,True,True,False,False,False,True,True,False,True,False,False,True,False,False,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,True,False,False,False,\n",
    "    False,False,False,False,False,False,False,False,False,True,False,False,False,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,True,False,False,False,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,False,False,True,True,True,False,False,True,False,False,False,False,False,False,False,True,False,False,True,False,False,False,False,False,False,False,False,False,False,False,True,False,False,True,False,False,False,True,False,False,False,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,True,True,False,False,True,False,True,False,False,False,False,False,False,False,True,False,True,True,False,False,False])\n",
    "    weatherMonthly=weatherMonthly.astype(int)\n",
    "    weatherYearly= np.array([False,True,True,True,False,True,False,False,False,False,True,True,False,False,True,True,True,True,False,False,False,True,False,True,True,False,True,True,True,False,False,True,True])\n",
    "    weatherYearly=weatherYearly.astype(int)\n",
    "    #For a month\n",
    "    fprMonth,missedMonth,accuracy1=realWorld(\"weather_dataset.csv\",weatherMonthly,30,\"Label_Rain\",detectorNames)\n",
    "    # tableToLatex(fprMonth,[\"Month\"],detectorNames,\"FPR Weather Month.txt\")\n",
    "    # tableToLatex(missedMonth,[\"Month\"],detectorNames,\"Missed Weather Month.txt\")\n",
    "    #For a year\n",
    "    fprYear,missedYear,accuracy2= realWorld(\"weather_dataset.csv\",weatherYearly,365,\"Label_Rain\",detectorNames)\n",
    "    fprs=[fprMonth,fprYear]\n",
    "    missed=[missedMonth,missedYear]\n",
    "    accuracies=[accuracy1,accuracy2]\n",
    "    # tableToLatex(fprYear,[\"Year\"],detectorNames,\"FPR Weather Year.txt\")\n",
    "    # tableToLatex(missedYear,[\"Year\"],detectorNames,\"Missed Weather Year.txt\")\n",
    "    return fprs,missed,accuracies\n",
    "\n",
    "#print(testWeather())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def testAirplanes():\n",
    "\n",
    "#17000 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "get the preprocessed things\n",
      "       Unnamed: 0      TEMP      DEWP       SLP     VISIB      WDSP     MXSPD  \\\n",
      "0        0.000000  0.349328  0.454985  0.003725  0.068548  0.315412  0.010120   \n",
      "1        0.000055  0.367562  0.443369  0.003936  0.217742  0.422939  0.016232   \n",
      "2        0.000110  0.342610  0.408519  0.004257  0.370968  0.283154  0.012124   \n",
      "3        0.000165  0.351248  0.415295  0.003770  0.423387  0.236559  0.020140   \n",
      "4        0.000220  0.322457  0.367861  0.004135  0.391129  0.372760  0.027054   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "18154    0.999780  0.486564  0.465634  0.002616  0.798387  0.161290  0.014028   \n",
      "18155    0.999835  0.369482  0.405615  0.003115  0.633065  0.369176  0.017936   \n",
      "18156    0.999890  0.245681  0.279768  0.003260  0.625000  0.372760  0.016032   \n",
      "18157    0.999945  0.182342  0.176186  0.003758  0.737903  0.491039  0.023046   \n",
      "18158    1.000000  0.092131  0.098742  0.005011  0.657258  0.164875  0.009920   \n",
      "\n",
      "            MAX       MIN  \n",
      "0      0.003977  0.399428  \n",
      "1      0.003887  0.390848  \n",
      "2      0.003777  0.390848  \n",
      "3      0.004876  0.372736  \n",
      "4      0.004286  0.353670  \n",
      "...         ...       ...  \n",
      "18154  0.006984  0.459485  \n",
      "18155  0.005885  0.334604  \n",
      "18156  0.003407  0.259295  \n",
      "18157  0.003207  0.183985  \n",
      "18158  0.001998  0.106768  \n",
      "\n",
      "[18159 rows x 9 columns]\n",
      "tonumpy.\n",
      "swag\n",
      "optimized neighbors for this is: 33\n",
      "optimized neighbors for this is: 33\n",
      "next detector\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fprWeather, missWeather, accWeather\u001b[39m=\u001b[39m testWeather((\u001b[39m\"\u001b[39;49m\u001b[39mMD3V1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mMD3V2\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mMD3_Tree\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mMD3_KN\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mFuzzy_Tree\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mFuzzy_K\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[1;32mIn[63], line 149\u001b[0m, in \u001b[0;36mtestWeather\u001b[1;34m(detectorNames)\u001b[0m\n\u001b[0;32m    147\u001b[0m weatherYearly\u001b[39m=\u001b[39mweatherYearly\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m    148\u001b[0m \u001b[39m#For a month\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m fprMonth,missedMonth,accuracy1\u001b[39m=\u001b[39mrealWorld(\u001b[39m\"\u001b[39;49m\u001b[39mweather_dataset.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,weatherMonthly,\u001b[39m30\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mLabel_Rain\u001b[39;49m\u001b[39m\"\u001b[39;49m,detectorNames)\n\u001b[0;32m    150\u001b[0m \u001b[39m# tableToLatex(fprMonth,[\"Month\"],detectorNames,\"FPR Weather Month.txt\")\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39m# tableToLatex(missedMonth,[\"Month\"],detectorNames,\"Missed Weather Month.txt\")\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39m#For a year\u001b[39;00m\n\u001b[0;32m    153\u001b[0m fprYear,missedYear,accuracy2\u001b[39m=\u001b[39m realWorld(\u001b[39m\"\u001b[39m\u001b[39mweather_dataset.csv\u001b[39m\u001b[39m\"\u001b[39m,weatherYearly,\u001b[39m365\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mLabel_Rain\u001b[39m\u001b[39m\"\u001b[39m,detectorNames)\n",
      "Cell \u001b[1;32mIn[63], line 62\u001b[0m, in \u001b[0;36mrealWorld\u001b[1;34m(link, realDrifts, batchSize, className, detectorNames, tooBig)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mfor\u001b[39;00m detector \u001b[39min\u001b[39;00m detectors:\n\u001b[0;32m     61\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnext detector\u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 62\u001b[0m         detector\u001b[39m.\u001b[39;49mtrain(trainData,trainLabels)\n\u001b[0;32m     64\u001b[0m testData,testLabels \u001b[39m=\u001b[39m getTestBatches(link,data,labels)\n\u001b[0;32m     65\u001b[0m testBatches \u001b[39m=\u001b[39m divideIntoBatchesOfX(testData,batchSize)\n",
      "Cell \u001b[1;32mIn[56], line 182\u001b[0m, in \u001b[0;36mDriftDetector.train\u001b[1;34m(self, data, labels)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m,data,labels):\n\u001b[0;32m    181\u001b[0m     \u001b[39m#If we pass stuff yea.\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     avAc,stdAc,avDens,stdDens\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mKXVal(data,labels,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC)\n\u001b[0;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavAc\u001b[39m=\u001b[39mavAc\n\u001b[0;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdAc\u001b[39m=\u001b[39mstdAc\n",
      "Cell \u001b[1;32mIn[56], line 69\u001b[0m, in \u001b[0;36mMDDriftDetector.KXVal\u001b[1;34m(self, data, labels, K, *classifierSettings)\u001b[0m\n\u001b[0;32m     67\u001b[0m trainData \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(splitData[:i]\u001b[39m+\u001b[39msplitData[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:])\n\u001b[0;32m     68\u001b[0m trainLabels\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(splitLabels[:i]\u001b[39m+\u001b[39msplitLabels[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:])\n\u001b[1;32m---> 69\u001b[0m dens,acc\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mCrossValid(trainData,splitData[i],trainLabels,splitLabels[i],classifierSettings)\n\u001b[0;32m     70\u001b[0m accuracies[i]\u001b[39m=\u001b[39m acc\n\u001b[0;32m     71\u001b[0m densities[i] \u001b[39m=\u001b[39m dens\n",
      "Cell \u001b[1;32mIn[56], line 80\u001b[0m, in \u001b[0;36mMDDriftDetector.CrossValid\u001b[1;34m(self, trainData, testData, trainLabels, testLabels, classifierSettings)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mCrossValid\u001b[39m(\u001b[39mself\u001b[39m,trainData,testData,trainLabels,testLabels, classifierSettings):\n\u001b[0;32m     79\u001b[0m     classifier\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainClassifier(trainData,trainLabels,classifierSettings)\n\u001b[1;32m---> 80\u001b[0m     density \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfindMarginDensity(trainData,classifier)\n\u001b[0;32m     81\u001b[0m     score\u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mscore(testData,testLabels)\n\u001b[0;32m     82\u001b[0m     \u001b[39m#print(score)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[56], line 148\u001b[0m, in \u001b[0;36mDriftDetector.findMarginDensity\u001b[1;34m(self, batch, svm)\u001b[0m\n\u001b[0;32m    146\u001b[0m marginDensity\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m vect \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m--> 148\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mabs(svm\u001b[39m.\u001b[39;49mdecision_function([vect]))\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    149\u001b[0m         marginDensity\u001b[39m=\u001b[39m marginDensity\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m marginDensity\u001b[39m/\u001b[39mbatch\u001b[39m.\u001b[39msize\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\_device_offload.py:181\u001b[0m, in \u001b[0;36mwrap_output_data.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     usm_iface \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(data[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m__sycl_usm_array_interface__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 181\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m usm_iface \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m _copy_to_usm(usm_iface[\u001b[39m'\u001b[39m\u001b[39msyclobj\u001b[39m\u001b[39m'\u001b[39m], result)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\svm\\svc.py:161\u001b[0m, in \u001b[0;36mSVC.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m Version(sklearn_version) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 161\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(\u001b[39mself\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msvm.SVC.decision_function\u001b[39;49m\u001b[39m'\u001b[39;49m, {\n\u001b[0;32m    162\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39monedal\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m_onedal_decision_function,\n\u001b[0;32m    163\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39msklearn\u001b[39;49m\u001b[39m'\u001b[39;49m: sklearn_SVC\u001b[39m.\u001b[39;49mdecision_function,\n\u001b[0;32m    164\u001b[0m }, X)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\_device_offload.py:158\u001b[0m, in \u001b[0;36mdispatch\u001b[1;34m(obj, method_name, branches, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msklearn.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mget_patch_message(backend,\u001b[39m \u001b[39mq,\u001b[39m \u001b[39mcpu_fallback)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39monedal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m branches[backend](obj, \u001b[39m*\u001b[39mhostargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhostkwargs, queue\u001b[39m=\u001b[39mq)\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msklearn\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m branches[backend](obj, \u001b[39m*\u001b[39mhostargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhostkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\svm\\svc.py:234\u001b[0m, in \u001b[0;36mSVC._onedal_decision_function\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_onedal_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X, queue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_onedal_estimator\u001b[39m.\u001b[39;49mdecision_function(X, queue\u001b[39m=\u001b[39;49mqueue)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\onedal\\svm\\svm.py:406\u001b[0m, in \u001b[0;36mSVC.decision_function\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X, queue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_decision_function(X, _backend\u001b[39m.\u001b[39;49msvm\u001b[39m.\u001b[39;49mclassification, queue)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\onedal\\svm\\svm.py:308\u001b[0m, in \u001b[0;36mBaseSVM._decision_function\u001b[1;34m(self, X, module, queue)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X, module, queue):\n\u001b[0;32m    307\u001b[0m     _check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 308\u001b[0m     X \u001b[39m=\u001b[39m _check_array(X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m    309\u001b[0m                      force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    310\u001b[0m     _check_n_features(\u001b[39mself\u001b[39m, X, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    312\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\onedal\\datatypes\\validation.py:105\u001b[0m, in \u001b[0;36m_check_array\u001b[1;34m(array, dtype, accept_sparse, order, copy, force_all_finite, ensure_2d, accept_large_sparse)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_array\u001b[39m(array, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m, accept_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    101\u001b[0m                  copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m                  ensure_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    103\u001b[0m     \u001b[39m# TODO\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m check_array\n\u001b[1;32m--> 105\u001b[0m     array \u001b[39m=\u001b[39m check_array(array\u001b[39m=\u001b[39;49marray, dtype\u001b[39m=\u001b[39;49mdtype, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    106\u001b[0m                         order\u001b[39m=\u001b[39;49morder, copy\u001b[39m=\u001b[39;49mcopy, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    107\u001b[0m                         ensure_2d\u001b[39m=\u001b[39;49mensure_2d, accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse)\n\u001b[0;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(array):\n\u001b[0;32m    110\u001b[0m         \u001b[39mreturn\u001b[39;00m array\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fprWeather, missWeather, accWeather= testWeather((\"MD3V1\",\"MD3V2\",\"MD3_Tree\",\"MD3_KN\",\"Fuzzy_Tree\",\"Fuzzy_K\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fprWeather' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# [array([.99699,1.        , 1.        , 0.92192192, 1.        , 0.82882883]), array([.93333,1., 1., 1., 1., 1.])]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# [array([0,0.        , 0.        , 0.05714286, 0.        , 0.17142857]), array([0,0.11111111, 0.        , 0.05555556, 0.        , 0.05555556])]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# [array([1,1.        , 1.        , 0.94285714, 1.        , 0.82857143]), array([1,0.88888889, 1.        , 0.94444444, 1.        , 0.94444444])]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# print(fprWeather)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# print(accWeather)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m tableToLatex(fprWeather,np\u001b[39m.\u001b[39marray([\u001b[39m\"\u001b[39m\u001b[39mMonthly\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mYearly\u001b[39m\u001b[39m\"\u001b[39m]) ,detectorNames,\u001b[39m\"\u001b[39m\u001b[39mFPRWeather.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m tableToLatex(accWeather,np\u001b[39m.\u001b[39marray([\u001b[39m\"\u001b[39m\u001b[39mMonthly\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mYearly\u001b[39m\u001b[39m\"\u001b[39m]) ,detectorNames,\u001b[39m\"\u001b[39m\u001b[39mAccWeather.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m fprElec,missedElec,accelec\u001b[39m=\u001b[39m testElec(detectorNames)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fprWeather' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# [array([.99699,1.        , 1.        , 0.92192192, 1.        , 0.82882883]), array([.93333,1., 1., 1., 1., 1.])]\n",
    "# [array([0,0.        , 0.        , 0.05714286, 0.        , 0.17142857]), array([0,0.11111111, 0.        , 0.05555556, 0.        , 0.05555556])]\n",
    "# [array([1,1.        , 1.        , 0.94285714, 1.        , 0.82857143]), array([1,0.88888889, 1.        , 0.94444444, 1.        , 0.94444444])]\n",
    "\n",
    "# detectorNames=np.array([\"MD3_V1\",\"MD3_V2\",\"MD3_Tree\",\"MD3_KN\",\"Fuzzy_Tree\",\"Fuzzy_KN\"])\n",
    "\n",
    "# fprWeather =np.array([[0.996997,1.,1.,0.86486486, 1.,0.78378378],[0.93333333, 1., 1., 0.8, 1., 0.93333333]])\n",
    "# #[[0., 0., 0., 0.15714286, 0.,0.17142857], [0., 0.11111111, 0., 0.16666667, 0.,0.]]\n",
    "# accWeather= np.array([[1., 1., 1., 0.84285714, 1.,0.82857143], [1., 0.88888889, 1., 0.83333333, 1.,1.]])\n",
    "\n",
    "# print(fprWeather)\n",
    "# print(accWeather)\n",
    "tableToLatex(fprWeather,np.array([\"Monthly\",\"Yearly\"]) ,detectorNames,\"FPRWeather.txt\")\n",
    "tableToLatex(accWeather,np.array([\"Monthly\",\"Yearly\"]) ,detectorNames,\"AccWeather.txt\")\n",
    "fprElec,missedElec,accelec= testElec(detectorNames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.92592593 1.         0.74074074 1.         0.44444444]\n",
      "[0.         0.05357143 0.         0.16071429 0.         0.21428571]\n",
      "[1.         0.94642857 1.         0.83928571 1.         0.78571429]\n",
      "            Elec FPR\n",
      "MD3_V1      0.962963\n",
      "MD3_V2      0.962963\n",
      "MD3_Tree    1.000000\n",
      "MD3_KN      1.000000\n",
      "Fuzzy_Tree  1.000000\n",
      "Fuzzy_KN    1.000000\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Elec FPR \\\\\n",
      "\\midrule\n",
      "MD3\\_V1     &  0.962963 \\\\\n",
      "MD3\\_V2     &  0.962963 \\\\\n",
      "MD3\\_Tree   &  1.000000 \\\\\n",
      "MD3\\_KN     &  1.000000 \\\\\n",
      "Fuzzy\\_Tree &  1.000000 \\\\\n",
      "Fuzzy\\_KN   &  1.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "            Elec Acc\n",
      "MD3_V1      1.000000\n",
      "MD3_V2      0.892857\n",
      "MD3_Tree    1.000000\n",
      "MD3_KN      1.000000\n",
      "Fuzzy_Tree  0.982143\n",
      "Fuzzy_KN    1.000000\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Elec Acc \\\\\n",
      "\\midrule\n",
      "MD3\\_V1     &  1.000000 \\\\\n",
      "MD3\\_V2     &  0.892857 \\\\\n",
      "MD3\\_Tree   &  1.000000 \\\\\n",
      "MD3\\_KN     &  1.000000 \\\\\n",
      "Fuzzy\\_Tree &  0.982143 \\\\\n",
      "Fuzzy\\_KN   &  1.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapti\\AppData\\Local\\Temp\\ipykernel_22296\\467450257.py:6: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  string = df.to_latex()\n",
      "C:\\Users\\bapti\\AppData\\Local\\Temp\\ipykernel_22296\\467450257.py:6: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  string = df.to_latex()\n"
     ]
    }
   ],
   "source": [
    "# [1.         0.92592593 1.         0.74074074 1.         0.44444444]\n",
    "# [0.         0.05357143 0.         0.16071429 0.         0.21428571]\n",
    "# [1.         0.94642857 1.         0.83928571 1.         0.78571429]\n",
    "\n",
    "#Elec K=5\n",
    "elecFPR=np.array([0.96296296 ,0.96296296 ,1.     ,    1.  ,       1.,         1.        ])\n",
    "#[0.         0.10714286 0.         0.         0.01785714 0.        ]\n",
    "elecAcc=np.array([1.  ,       0.89285714, 1.     ,    1.  ,       0.98214286 ,1.        ])\n",
    "#Elec K=17\n",
    "\n",
    "print(fprElec)\n",
    "print(missedElec)\n",
    "print(accelec)\n",
    "tableToLatex(elecFPR,detectorNames,np.array([\"Elec FPR\"]),\"FPRElec.txt\")\n",
    "tableToLatex(elecAcc,detectorNames,np.array([\"Elec Acc\"]),\"AccElec.txt\")\n",
    "tableToExcel(elecFPR,detectorNames,np.array([\"Elec FPR\"]),\"FPRElec.txt\")\n",
    "tableToExcel(elecFPR,detectorNames,np.array([\"Elec FPR\"]),\"FPRElec.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "get the preprocessed things\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m         spdriftLengths[x][num\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39m# print(fprElec)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# print(missedElec)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# print(accelec)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m fprSpam,missedSpam,spamacc \u001b[39m=\u001b[39m testSpam(spdriftLengths,detectorNames)\n",
      "Cell \u001b[1;32mIn[63], line 124\u001b[0m, in \u001b[0;36mtestSpam\u001b[1;34m(realDrifts, detectorNames)\u001b[0m\n\u001b[0;32m    122\u001b[0m accuracies \u001b[39m=\u001b[39m []\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(realDrifts)):\n\u001b[1;32m--> 124\u001b[0m     fpr,missed,accuracy \u001b[39m=\u001b[39m realWorld(\u001b[39m\"\u001b[39;49m\u001b[39mspam_dataset.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,realDrifts[ind],batchLengths[ind],\u001b[39m\"\u001b[39;49m\u001b[39mACTUAL_LABEL\u001b[39;49m\u001b[39m\"\u001b[39;49m,detectorNames)\n\u001b[0;32m    125\u001b[0m     fprs\u001b[39m=\u001b[39m fprs \u001b[39m+\u001b[39m fpr\n\u001b[0;32m    126\u001b[0m     misseds\u001b[39m=\u001b[39m misseds \u001b[39m+\u001b[39m missed\n",
      "Cell \u001b[1;32mIn[63], line 47\u001b[0m, in \u001b[0;36mrealWorld\u001b[1;34m(link, realDrifts, batchSize, className, detectorNames, tooBig)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrealWorld\u001b[39m(link,realDrifts,batchSize,className,detectorNames,tooBig\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 47\u001b[0m     data, labels \u001b[39m=\u001b[39m fromFiletoData(link,className,\u001b[39m\"\u001b[39;49m\u001b[39mOrdinal\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     48\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mswag\u001b[39m\u001b[39m\"\u001b[39m,flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     50\u001b[0m     trainData,trainLabels \u001b[39m=\u001b[39m getTrainSet(link,data,labels)\n",
      "Cell \u001b[1;32mIn[57], line 95\u001b[0m, in \u001b[0;36mfromFiletoData\u001b[1;34m(link, className, encoder)\u001b[0m\n\u001b[0;32m     93\u001b[0m scaler\u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[0;32m     94\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mget the preprocessed things\u001b[39m\u001b[39m\"\u001b[39m,flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m df[df\u001b[39m.\u001b[39;49mcolumns] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(df[df\u001b[39m.\u001b[39mcolumns])\n\u001b[0;32m     96\u001b[0m \u001b[39m#df= scaler.fit_transform(df)\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[39mprint\u001b[39m(df,flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:3968\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3966\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   3967\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[1;32m-> 3968\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   3970\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:4019\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4016\u001b[0m         \u001b[39mself\u001b[39m[col] \u001b[39m=\u001b[39m value\n\u001b[0;32m   4018\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 4019\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iset_not_inplace(key, value)\n\u001b[0;32m   4021\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mndim(value) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4022\u001b[0m     \u001b[39m# list of lists\u001b[39;00m\n\u001b[0;32m   4023\u001b[0m     value \u001b[39m=\u001b[39m DataFrame(value)\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:4049\u001b[0m, in \u001b[0;36mDataFrame._iset_not_inplace\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4046\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4048\u001b[0m     \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n\u001b[1;32m-> 4049\u001b[0m         \u001b[39mself\u001b[39;49m[col] \u001b[39m=\u001b[39m igetitem(value, i)\n\u001b[0;32m   4051\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4053\u001b[0m     ilocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_indexer_non_unique(key)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:4187\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4184\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   4185\u001b[0m             value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(value, (\u001b[39mlen\u001b[39m(existing_piece\u001b[39m.\u001b[39mcolumns), \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT\n\u001b[1;32m-> 4187\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_mgr(key, value)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:4146\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39minsert(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis), key, value)\n\u001b[0;32m   4145\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4146\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iset_item_mgr(loc, value)\n\u001b[0;32m   4148\u001b[0m \u001b[39m# check if we are modifying a copy\u001b[39;00m\n\u001b[0;32m   4149\u001b[0m \u001b[39m# try to set first as we want an invalid\u001b[39;00m\n\u001b[0;32m   4150\u001b[0m \u001b[39m# value exception to occur first\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\frame.py:4136\u001b[0m, in \u001b[0;36mDataFrame._iset_item_mgr\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   4132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iset_item_mgr\u001b[39m(\n\u001b[0;32m   4133\u001b[0m     \u001b[39mself\u001b[39m, loc: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mslice\u001b[39m \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray, value, inplace: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   4134\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4135\u001b[0m     \u001b[39m# when called from _set_item_mgr loc can be anything returned from get_loc\u001b[39;00m\n\u001b[1;32m-> 4136\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49miset(loc, value, inplace\u001b[39m=\u001b[39;49minplace)\n\u001b[0;32m   4137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1268\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1266\u001b[0m     removed_blknos\u001b[39m.\u001b[39mappend(blkno_l)\n\u001b[0;32m   1267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1268\u001b[0m     nb \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mdelete(blk_locs)\n\u001b[0;32m   1269\u001b[0m     blocks_tup \u001b[39m=\u001b[39m (\n\u001b[0;32m   1270\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks[:blkno_l] \u001b[39m+\u001b[39m (nb,) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks[blkno_l \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :]\n\u001b[0;32m   1271\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m blocks_tup\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1921\u001b[0m, in \u001b[0;36mNumpyBlock.delete\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdelete\u001b[39m(\u001b[39mself\u001b[39m, loc) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Block:\n\u001b[1;32m-> 1921\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdelete(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, loc, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m   1922\u001b[0m     mgr_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr_locs\u001b[39m.\u001b[39mdelete(loc)\n\u001b[0;32m   1923\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(values, placement\u001b[39m=\u001b[39mmgr_locs, ndim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdelete\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\numpy\\lib\\function_base.py:5223\u001b[0m, in \u001b[0;36mdelete\u001b[1;34m(arr, obj, axis)\u001b[0m\n\u001b[0;32m   5221\u001b[0m     slobj2 \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)]\u001b[39m*\u001b[39mndim\n\u001b[0;32m   5222\u001b[0m     slobj2[axis] \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(obj\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 5223\u001b[0m     new[\u001b[39mtuple\u001b[39;49m(slobj)] \u001b[39m=\u001b[39m arr[\u001b[39mtuple\u001b[39m(slobj2)]\n\u001b[0;32m   5224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5225\u001b[0m     \u001b[39mif\u001b[39;00m obj\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "spamDrift=[[7, 8, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "[11, 14, 15, 16, 17, 19, 20, 21, 22, 23, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58],\n",
    "[10, 14, 21, 26, 32, 33, 35, 36, 37, 39, 40, 41, 42, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 67, 68, 72, 73, 76, 78, 80, 81, 82, 83,\n",
    " 85, 86, 87, 88, 91, 92, 93, 95, 97, 98, 99, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 130, 131, 132, 135, 136, 137, 138, 139, 141, 142, 143, 145]]\n",
    "\n",
    "spambatlengths=[29,58,146] #146 147\n",
    "spdrift1 = np.zeros(29)\n",
    "spdrift2 = np.zeros(58)\n",
    "spdrift3 = np.zeros(146)\n",
    "spdriftLengths=[spdrift1,spdrift2,spdrift3]\n",
    "\n",
    "for x in range(len(spamDrift)):\n",
    "    for num in spamDrift[x]:\n",
    "        spdriftLengths[x][num-1]=1\n",
    "\n",
    "# print(fprElec)\n",
    "# print(missedElec)\n",
    "# print(accelec)\n",
    "fprSpam,missedSpam,spamacc = testSpam(spdriftLengths,detectorNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Air FPR\n",
      "MD3V1           0.0\n",
      "MD3V2           0.0\n",
      "MD3_Tree        1.0\n",
      "MD3KNN          1.0\n",
      "Fuzzy_Tree      1.0\n",
      "FuzzyKNN        0.0\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Air FPR \\\\\n",
      "\\midrule\n",
      "MD3V1      &      0.0 \\\\\n",
      "MD3V2      &      0.0 \\\\\n",
      "MD3\\_Tree   &      1.0 \\\\\n",
      "MD3KNN     &      1.0 \\\\\n",
      "Fuzzy\\_Tree &      1.0 \\\\\n",
      "FuzzyKNN   &      0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "            Air Acc\n",
      "MD3V1           0.0\n",
      "MD3V2           0.0\n",
      "MD3_Tree        1.0\n",
      "MD3KNN          1.0\n",
      "Fuzzy_Tree      1.0\n",
      "FuzzyKNN        0.0\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Air Acc \\\\\n",
      "\\midrule\n",
      "MD3V1      &      0.0 \\\\\n",
      "MD3V2      &      0.0 \\\\\n",
      "MD3\\_Tree   &      1.0 \\\\\n",
      "MD3KNN     &      1.0 \\\\\n",
      "Fuzzy\\_Tree &      1.0 \\\\\n",
      "FuzzyKNN   &      0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapti\\AppData\\Local\\Temp\\ipykernel_29496\\467450257.py:6: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  string = df.to_latex()\n",
      "C:\\Users\\bapti\\AppData\\Local\\Temp\\ipykernel_29496\\467450257.py:6: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  string = df.to_latex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "get the preprocessed things\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0    Flight      Time    Length  Airline_b'9E'  \\\n",
      "0         0.000000  0.034302  0.003499  0.312977            0.0   \n",
      "1         0.000002  0.199283  0.003499  0.338931            0.0   \n",
      "2         0.000004  0.307052  0.006998  0.251908            0.0   \n",
      "3         0.000006  0.315500  0.006998  0.297710            0.0   \n",
      "4         0.000007  0.013695  0.013996  0.308397            0.0   \n",
      "...            ...       ...       ...       ...            ...   \n",
      "539378    0.999993  0.022655  1.000000  0.497710            0.0   \n",
      "539379    0.999994  0.050813  1.000000  0.465649            0.0   \n",
      "539380    0.999996  0.077819  1.000000  0.389313            0.0   \n",
      "539381    0.999998  0.009855  1.000000  0.477863            0.0   \n",
      "539382    1.000000  0.184436  1.000000  0.459542            0.0   \n",
      "\n",
      "        Airline_b'AA'  Airline_b'AS'  Airline_b'B6'  Airline_b'CO'  \\\n",
      "0                 0.0            0.0            0.0            1.0   \n",
      "1                 0.0            0.0            0.0            0.0   \n",
      "2                 1.0            0.0            0.0            0.0   \n",
      "3                 1.0            0.0            0.0            0.0   \n",
      "4                 0.0            1.0            0.0            0.0   \n",
      "...               ...            ...            ...            ...   \n",
      "539378            0.0            0.0            0.0            1.0   \n",
      "539379            0.0            0.0            0.0            0.0   \n",
      "539380            0.0            0.0            0.0            0.0   \n",
      "539381            0.0            0.0            0.0            0.0   \n",
      "539382            0.0            0.0            0.0            0.0   \n",
      "\n",
      "        Airline_b'DL'  ...  Airline_b'FL'  Airline_b'HA'  Airline_b'MQ'  \\\n",
      "0                 0.0  ...            0.0            0.0            0.0   \n",
      "1                 0.0  ...            0.0            0.0            0.0   \n",
      "2                 0.0  ...            0.0            0.0            0.0   \n",
      "3                 0.0  ...            0.0            0.0            0.0   \n",
      "4                 0.0  ...            0.0            0.0            0.0   \n",
      "...               ...  ...            ...            ...            ...   \n",
      "539378            0.0  ...            0.0            0.0            0.0   \n",
      "539379            0.0  ...            1.0            0.0            0.0   \n",
      "539380            0.0  ...            1.0            0.0            0.0   \n",
      "539381            0.0  ...            0.0            0.0            0.0   \n",
      "539382            0.0  ...            0.0            0.0            0.0   \n",
      "\n",
      "        Airline_b'OH'  Airline_b'OO'  Airline_b'UA'  Airline_b'US'  \\\n",
      "0                 0.0            0.0            0.0            0.0   \n",
      "1                 0.0            0.0            0.0            1.0   \n",
      "2                 0.0            0.0            0.0            0.0   \n",
      "3                 0.0            0.0            0.0            0.0   \n",
      "4                 0.0            0.0            0.0            0.0   \n",
      "...               ...            ...            ...            ...   \n",
      "539378            0.0            0.0            0.0            0.0   \n",
      "539379            0.0            0.0            0.0            0.0   \n",
      "539380            0.0            0.0            0.0            0.0   \n",
      "539381            0.0            0.0            1.0            0.0   \n",
      "539382            0.0            0.0            0.0            1.0   \n",
      "\n",
      "        Airline_b'WN'  Airline_b'XE'  Airline_b'YV'  \n",
      "0                 0.0            0.0            0.0  \n",
      "1                 0.0            0.0            0.0  \n",
      "2                 0.0            0.0            0.0  \n",
      "3                 0.0            0.0            0.0  \n",
      "4                 0.0            0.0            0.0  \n",
      "...               ...            ...            ...  \n",
      "539378            0.0            0.0            0.0  \n",
      "539379            0.0            0.0            0.0  \n",
      "539380            0.0            0.0            0.0  \n",
      "539381            0.0            0.0            0.0  \n",
      "539382            0.0            0.0            0.0  \n",
      "\n",
      "[539383 rows x 22 columns]\n",
      "tonumpy.\n",
      "swag\n",
      "optimized neighbors for this is: 38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m tableToLatex(accair,detectorNames,np\u001b[39m.\u001b[39marray([\u001b[39m\"\u001b[39m\u001b[39mAir Acc\u001b[39m\u001b[39m\"\u001b[39m]),\u001b[39m\"\u001b[39m\u001b[39mAccAir.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m#[0.95454545 0.95454545] [0. 0.]\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m fprair,missedair,accair \u001b[39m=\u001b[39m testAirplane(detectorNames,tooBig\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(fprair)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(missedair)\n",
      "Cell \u001b[1;32mIn[11], line 134\u001b[0m, in \u001b[0;36mtestAirplane\u001b[1;34m(detectorNames, tooBig)\u001b[0m\n\u001b[0;32m    132\u001b[0m realAirplaneDrifts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m22\u001b[39m)\n\u001b[0;32m    133\u001b[0m realAirplaneDrifts[\u001b[39m0\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m--> 134\u001b[0m fpr,missed,accuracy \u001b[39m=\u001b[39m realWorld(\u001b[39m\"\u001b[39;49m\u001b[39mairline_dataset.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,realAirplaneDrifts,\u001b[39m17000\u001b[39;49m ,\u001b[39m\"\u001b[39;49m\u001b[39mDelay\u001b[39;49m\u001b[39m\"\u001b[39;49m,detectorNames,tooBig\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m fpr, missed, accuracy\n",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m, in \u001b[0;36mrealWorld\u001b[1;34m(link, realDrifts, batchSize, className, detectorNames, tooBig)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mswag\u001b[39m\u001b[39m\"\u001b[39m,flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m trainData,trainLabels \u001b[39m=\u001b[39m getTrainSet(link,data,labels)\n\u001b[0;32m     51\u001b[0m detectors\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([\n\u001b[0;32m     52\u001b[0m MD3V1(\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m.075\u001b[39m,toobig\u001b[39m=\u001b[39mtooBig), \n\u001b[0;32m     53\u001b[0m DriftDetector(\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m5\u001b[39m,toobig\u001b[39m=\u001b[39mtooBig),\n\u001b[0;32m     54\u001b[0m EnsembleMDDriftDetector(\u001b[39m5\u001b[39m,tree\u001b[39m.\u001b[39mDecisionTreeClassifier(),\u001b[39m20\u001b[39m,trunc(data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m),\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m     55\u001b[0m EnsembleMDDriftDetector(\u001b[39m5\u001b[39m,createBestKNNDetector(trainData,trainLabels,\u001b[39m40\u001b[39m),\u001b[39m20\u001b[39m,trunc(data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m),\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m     56\u001b[0m FuzzyDetector(\u001b[39m5\u001b[39m,tree\u001b[39m.\u001b[39mDecisionTreeClassifier(),\u001b[39m20\u001b[39m,trunc(data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m),\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m---> 57\u001b[0m FuzzyDetector(\u001b[39m5\u001b[39m,createBestKNNDetector(trainData,trainLabels,\u001b[39m40\u001b[39;49m),\u001b[39m20\u001b[39m,trunc(data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m),\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m ])\n\u001b[0;32m     59\u001b[0m \u001b[39mfor\u001b[39;00m detector \u001b[39min\u001b[39;00m detectors:\n\u001b[0;32m     60\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnext detector\u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 353\u001b[0m, in \u001b[0;36mcreateBestKNNDetector\u001b[1;34m(data, labels, maxK)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m k_range:\n\u001b[0;32m    352\u001b[0m     model \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39mk)\n\u001b[1;32m--> 353\u001b[0m     k_scores[k]\u001b[39m=\u001b[39m cross_val_score(model, data, labels, cv\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m    354\u001b[0m     \u001b[39m#print(k_scores[k])\u001b[39;00m\n\u001b[0;32m    356\u001b[0m optimizedNeighbors\u001b[39m=\u001b[39m k_scores\u001b[39m.\u001b[39margmax()\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[0;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    770\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:117\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         score \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39m_score(cached_call, estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    116\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m         score \u001b[39m=\u001b[39m scorer(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m     scores[name] \u001b[39m=\u001b[39m score\n\u001b[0;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:444\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_passthrough_scorer\u001b[39m(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    443\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39mscore(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\base.py:649\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 649\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\_device_offload.py:181\u001b[0m, in \u001b[0;36mwrap_output_data.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     usm_iface \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(data[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m__sycl_usm_array_interface__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 181\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m usm_iface \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m _copy_to_usm(usm_iface[\u001b[39m'\u001b[39m\u001b[39msyclobj\u001b[39m\u001b[39m'\u001b[39m], result)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\neighbors\\knn_classification.py:228\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mif\u001b[39;00m sklearn_check_version(\u001b[39m\"\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(\u001b[39mself\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mneighbors.KNeighborsClassifier.predict\u001b[39;49m\u001b[39m'\u001b[39;49m, {\n\u001b[0;32m    229\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39monedal\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m_onedal_predict,\n\u001b[0;32m    230\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39msklearn\u001b[39;49m\u001b[39m'\u001b[39;49m: sklearn_KNeighborsClassifier\u001b[39m.\u001b[39;49mpredict,\n\u001b[0;32m    231\u001b[0m }, X)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\_device_offload.py:158\u001b[0m, in \u001b[0;36mdispatch\u001b[1;34m(obj, method_name, branches, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msklearn.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mget_patch_message(backend,\u001b[39m \u001b[39mq,\u001b[39m \u001b[39mcpu_fallback)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39monedal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m branches[backend](obj, \u001b[39m*\u001b[39mhostargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhostkwargs, queue\u001b[39m=\u001b[39mq)\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msklearn\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m branches[backend](obj, \u001b[39m*\u001b[39mhostargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhostkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\sklearnex\\neighbors\\knn_classification.py:394\u001b[0m, in \u001b[0;36mKNeighborsClassifier._onedal_predict\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_onedal_predict\u001b[39m(\u001b[39mself\u001b[39m, X, queue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 394\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_onedal_estimator\u001b[39m.\u001b[39;49mpredict(X, queue\u001b[39m=\u001b[39;49mqueue)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\onedal\\neighbors\\neighbors.py:463\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X, queue)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_onedal_params(X)\n\u001b[1;32m--> 463\u001b[0m prediction_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_onedal_predict(onedal_model, X, params, queue\u001b[39m=\u001b[39;49mqueue)\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_ \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m gpu_device:\n\u001b[0;32m    465\u001b[0m     responses \u001b[39m=\u001b[39m prediction_result\u001b[39m.\u001b[39mprediction\n",
      "File \u001b[1;32mc:\\Users\\bapti\\anaconda3\\envs\\env\\lib\\site-packages\\onedal\\neighbors\\neighbors.py:421\u001b[0m, in \u001b[0;36mKNeighborsClassifier._onedal_predict\u001b[1;34m(self, model, X, params, queue)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m         predict_alg \u001b[39m=\u001b[39m kdtree_knn_classification_prediction\n\u001b[1;32m--> 421\u001b[0m     \u001b[39mreturn\u001b[39;00m predict_alg(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\u001b[39m.\u001b[39;49mcompute(X, model)\n\u001b[0;32m    423\u001b[0m policy \u001b[39m=\u001b[39m _get_policy(queue, X)\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_onedal_model\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OrdinalEncoder\n",
    "fprair= [0., 0. ,1. ,1. ,1. ,0.]\n",
    "# [1. 1. 0. 0. 0. 1.]\n",
    "accair= [0., 0., 1., 1., 1., 0.]\n",
    "\n",
    "tableToLatex(fprair,detectorNames,np.array([\"Air FPR\"]),\"FPRAIR.txt\")\n",
    "tableToLatex(accair,detectorNames,np.array([\"Air Acc\"]),\"AccAir.txt\")\n",
    "\n",
    "tableToExcel(fprair,detectorNames,np.array([\"Air FPR\"]),\"FPRAIR.xmnls\")\n",
    "tableToExcel(accair,detectorNames,np.array([\"Air Acc\"]),\"AccAir.xmnls\")\n",
    "\n",
    "\n",
    "#[0.95454545 0.95454545] [0. 0.]\n",
    "fprair,missedair,accair = testAirplane(detectorNames,tooBig=True)\n",
    "print(fprair)\n",
    "print(missedair)\n",
    "print(accair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.2 1.  0.2 0.2 0.2 0.2 0.4 1.  1.  1.  1.  1.  0.2 0.2 0.2 0.2 0.4]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.2]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.2 1. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "#For\n",
    "\n",
    "\n",
    "# [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "#  [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
    "#  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "#  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "# [[1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.2 1. ]\n",
    "#  [1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  0. ]\n",
    "#  [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    "#  [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n",
    "\n",
    "sourceNames=np.array([\"sea A\",\"agraw1 A\",\"agraw2 A\",\"agraw1_05\",\"agraw1_1\",\"agraw1_5\",\n",
    "\"agraw1_10\",\"agraw1_20\",\"agraw2_05\",\"agraw2_1\",\"agraw2_5\",\"agraw2_10\",\"agraw2_20\",\n",
    "\"sea_05\",\"sea_1\",\"sea_5\",\"sea_10\",\"sea_20\"])\n",
    "\n",
    "resultsFPR= np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[0 ,0 ,0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]])\n",
    "resultsLatency= np.array([[0.2,0.2,1,0.2,.2,.2,.2,.4,1,1,1,1,1,.2,.2,.2,.2,.4],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.2,.2],[0,0,0,0,0,0,0,.2,0,0,0,0,0,0,0,0,0,0],[1.,1., 1.,1., 1. , 0. , 1. , 1. , 1., 1.,1. , 1. , 0. , 1. , 1.,  1., 0.2 ,1. ],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1. , 1.,  0. , 1. , 0. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0. , 0. , 1. , 1. , 1. , 0. ]])\n",
    "print(resultsLatency)\n",
    "\n",
    "\n",
    "fprAbrupt =resultsFPR[:,:3]\n",
    "latencyAbrupt = resultsLatency[:,:3]\n",
    "\n",
    "fprGradual = resultsFPR[:,-15:]\n",
    "latencyGradual=resultsLatency[:,-15:]\n",
    "\n",
    "fprsea = fprGradual[:,-5:]\n",
    "fprag1 = fprGradual[:,:5]\n",
    "fprag2 = fprGradual[:,5:10]\n",
    "latsea =latencyGradual[:,-5:]\n",
    "latag1 =latencyGradual[:,:5]\n",
    "latag2 = latencyGradual[:,5:10]\n",
    "\n",
    "\n",
    "colsAb=sourceNames[:3]\n",
    "colsGrad= sourceNames[-15:]\n",
    "colsGradSea = colsGrad[-5:]\n",
    "colsGradAg1 = colsGrad[:5]\n",
    "colsGradAg2 = colsGrad[5:10]\n",
    "\n",
    "detectorNames=np.array([\"MD3_V1\",\"MD3_V2\",\"MD3_Tree\",\"MD3_KN\",\"Fuzzy_Tree\",\"Fuzzy_KN\"])\n",
    "\n",
    "\n",
    "#All of them\n",
    "# tableToLatex(np.transpose(resultsFPR),sourceNames,detectorNames,\"FPRsSynthetic.txt\")\n",
    "# tableToLatex(np.transpose(resultsLatency),sourceNames,detectorNames,\"LatencySynthetic.txt\")\n",
    "\n",
    "tableToExcel(np.transpose(resultsFPR),sourceNames,detectorNames,\"faslepositivesSynthetic.xlsx\")\n",
    "tableToExcel(np.transpose(resultsLatency),sourceNames,detectorNames,\"LatencySSynthetic.xlsx\")\n",
    "\n",
    "# #abrupt\n",
    "# tableToLatex(fprAbrupt,detectorNames,colsAb,\"FPRsSyntheticAbrupt.txt\")\n",
    "# tableToLatex(latencyAbrupt,detectorNames,colsAb,\"LatencyAbrupt.txt\")\n",
    "\n",
    "# #Gradual\n",
    "# tableToLatex(fprsea,detectorNames,colsGradSea,\"FRPGradualSea.txt\")\n",
    "# tableToLatex(fprag1,detectorNames,colsGradAg1,\"FRPGradualAg1.txt\")\n",
    "# tableToLatex(fprag2,detectorNames,colsGradAg2,\"FRPGradualAg2.txt\")\n",
    "# tableToLatex(latsea,detectorNames,colsGradSea,\"LatencyGradualSea.txt\")\n",
    "# tableToLatex(latag1,detectorNames,colsGradAg1,\"LatencyGradualAg1.txt\")\n",
    "# tableToLatex(latag2,detectorNames,colsGradAg2,\"LatencyGradualAg2.txt\")\n",
    "#def tableToLatex(content,columNames,rowNames,fileToSave):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "27fd6a064d6c7c8082aaa95ab329c8297122ddbb839f6b085e9f9d2309e1bfb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
