{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1., -1.],\n",
      "       [-2., -1.],\n",
      "       [-3., -1.]]), array([[3., 1.],\n",
      "       [1., 1.],\n",
      "       [2., 1.]]), array([[2.5, 1. ],\n",
      "       [1.5, 1. ]])]\n",
      "[1]\n",
      "[-0.99957031 -1.00035156  1.00042969  0.99964844  1.00003906  1.00023437]\n",
      "[-1.  1.]\n",
      "[-0.99957031]\n",
      "[-1.00035156]\n",
      "[1.00042969]\n",
      "[0.99964844]\n",
      "[1.00003906]\n",
      "[1.00023437]\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel=\"linear\", C=1)\n",
    "clf2= svm.SVC(kernel=\"linear\", C=1)\n",
    "pipe = make_pipeline(StandardScaler(),clf)\n",
    "X = np.array([[-1, -1], [-2, -1],[-3,-1],[3,1], [1, 1], [2, 1],[2.5,1],[1.5,1]])\n",
    "Z = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "A = np.array([1, 1, 2,2])\n",
    "Y = np.array([1, 1, 1, 1, 2, 2,2,2])\n",
    "clf.fit(X,Y)\n",
    "clf2.fit(Z,A)\n",
    "R=np.array_split(X,3)\n",
    "print(R)\n",
    "# svm.Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "#                 ('svc', SVC(gamma='auto'))])\n",
    "\n",
    "print(clf.predict([[-.8,-1]]))\n",
    "vecotr= clf.support_vectors_\n",
    "vecotr2= clf2.support_vectors_\n",
    "print(clf.decision_function(vecotr))\n",
    "print(clf2.decision_function(vecotr2))\n",
    "for i in vecotr:\n",
    "    print(clf.decision_function([i]))\n",
    "#print(clf.decision_function([vecotr]))\n",
    "#print(clf.decision_function([vecotr2]))\n",
    "marginDensity= 0\n",
    "\n",
    "#initiializes drift detector\n",
    "class DriftDetector:\n",
    "    def __init__(self, data, labels,kernel,C,K):\n",
    "        svm= DriftDetector.trainSVM(data,labels,kernel,C)\n",
    "        self.svm= svm\n",
    "        density = DriftDetector.findMarginDensity(data,svm)\n",
    "        self.max=density\n",
    "        self.min=density\n",
    "        self.thresh=.075\n",
    "        #needed for other version.\n",
    "        avAc,stdAc,stdDens= DriftDetector.KXVal(data,labels,kernel,C,K)\n",
    "        self.density=density\n",
    "        self.avAc=avAc\n",
    "        self.stdAc=stdAc\n",
    "        self.stdDens=stdDens\n",
    "        self.stdDensThresh=1\n",
    "\n",
    "#needs to be adapted for window stuff.\n",
    "    def findMarginDensity(batch,svm):\n",
    "        #vector = svm.support_vectors_[:,0]\n",
    "        marginDensity=0\n",
    "        for vect in batch:\n",
    "            if np.abs(svm.decision_function([vect]))<=1:\n",
    "                marginDensity= marginDensity+1\n",
    "        return marginDensity/batch.size\n",
    "\n",
    "    def trainSVM(data,labels,kernel,C):\n",
    "        clf= svm.SVC(kernel=kernel,C=C)\n",
    "        clf.fit(data,labels)\n",
    "        return clf\n",
    "#1st version md3\n",
    "    def detectDrift(self,batch):\n",
    "        md2=self.findMarginDensity(batch)\n",
    "        if md2>self.max:\n",
    "            self.max=md2\n",
    "        if md2<self.min:\n",
    "            self.min= md2\n",
    "        if (self.max-self.min)>self.thresh:\n",
    "            return True\n",
    "        else: False\n",
    "    #multiclass? linear? etc. retrain once found problem.\n",
    "    def retrain(self,data,labels,kernel,C,K):\n",
    "        self.svm.fit(data,labels)\n",
    "        density = self.findMarginDensity(data)\n",
    "        self.max=density\n",
    "        self.min=density\n",
    "        avAc,stdAc,stdDens= DriftDetector.KXVal(data,labels,kernel,C,K)\n",
    "        self.density=density\n",
    "        self.avAc=avAc\n",
    "        self.stdAc=stdAc\n",
    "        self.stdDens=stdDens\n",
    "##cross avlidaton, gets the distribution components.\n",
    "    def KXVal(data, labels,kernel,C,K):\n",
    "        splitData=np.array_split(data,K)\n",
    "        splitLabels=np.array_split(labels,K)\n",
    "        accuracies = np.zeros()\n",
    "        densities = np.zeros\n",
    "        for i in range(K):\n",
    "            trainData=splitData[:i]+splitData[i:]\n",
    "            trainLabels=splitLabels[:i]+splitLabels[i:]\n",
    "            accuracies[i],densities[i]= DriftDetector.CrossValid(trainData,splitData[i],trainLabels,splitLabels[i],kernel,C)\n",
    "        averageAccuracy= np.average(accuracies)\n",
    "        standardDevAccuracy= np.std(accuracies)\n",
    "        standardDevDensity=np.std(densities)\n",
    "        return averageAccuracy, standardDevAccuracy,standardDevDensity\n",
    "\n",
    "#this is for batch, not sliding window. sliding window forgetting factor sus\n",
    "#here supposed to query an oracle callback function.\n",
    "    def calculateMD3drift(self,batch):\n",
    "        batchMD= DriftDetector.findMarginDensity(batch,self.svm)\n",
    "        if np.abs(batchMD-self.density)>self.stdDensThresh*self.stdDens:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def checkAccuracy(self,batch,labels):\n",
    "        if batch.size==labels.size:\n",
    "            score=self.svm.score(batch,labels)\n",
    "            if self.avAc-score>self.stdDensThresh*self.stdAc:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "            \n",
    "    # very inefficient, right now, creates new svm. need change the svm, so need to use class svm and fit.\n",
    "    def CrossValid(trainData,testData,trainLabels,testLabels,kernel,C):\n",
    "        svm= DriftDetector.trainSVM(trainData,trainLabels,kernel,C)\n",
    "        density = DriftDetector.findMarginDensity(trainData,svm)\n",
    "        score= svm.score(testData,testLabels)\n",
    "        return density, score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #need k cross validation. upgraded\n",
    "    #need the fuzzy algorithm -> basically same algo but using RS and fuzzy. majority voting.\n",
    "    ##need virtual margins implementation. inda dumb, just about confidence levels?\n",
    "    ##ask lorena: if the same but with different way to find classification, not ... if using window.\n",
    "    #non lineear margins... vrtual.\n",
    "    \n",
    "    \n",
    "dd= DriftDetector(X,Y,\"linear\",1)\n",
    "if dd.detectDrift(X):\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
