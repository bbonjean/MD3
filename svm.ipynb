{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import sklearn.svm as svm\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearnex import patch_sklearn \n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "patch_sklearn()\n",
    "clf = svm.SVC(kernel=\"linear\", C=1)\n",
    "clf2= svm.SVC(kernel=\"linear\", C=1)\n",
    "pipe = make_pipeline(StandardScaler(),clf)\n",
    "X = np.array([[-1, -1], [-2, -1],[-3,-1],[3,1], [1, 1], [2, 1],[2.5,1],[1.5,1]])\n",
    "Z = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "A = np.array([1, 1, 2,2])\n",
    "Y = np.array([1, 1, 2, 1, 2, 1,2,2])\n",
    "clf.fit(X,Y)\n",
    "clf2.fit(Z,A)\n",
    "R=np.array_split(X,3)\n",
    "#print(R)\n",
    "#ARF load, py.io\n",
    "# Target, and ordinal is good.\n",
    "# anaconda and jupyter notebook\n",
    "\n",
    "# svm.Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "#                 ('svc', SVC(gamma='auto'))])\n",
    "\n",
    "#print(clf.predict([[-.8,-1]]))\n",
    "vecotr= clf.support_vectors_\n",
    "vecotr2= clf2.support_vectors_\n",
    "#print(clf.decision_function(vecotr))\n",
    "#print(clf2.decision_function(vecotr2))\n",
    "marginDensity= 0\n",
    "\n",
    "#initiializes drift detector\n",
    "class DriftDetector:\n",
    "    def __init__(self, data, labels,kernel,C,K):\n",
    "        #needed for other version.\n",
    "        avAc,stdAc,stdDens= DriftDetector.KXVal(data,labels,kernel,C,K)\n",
    "        self.avAc=avAc\n",
    "        self.stdAc=stdAc\n",
    "        self.stdDens=stdDens\n",
    "        svm= DriftDetector.trainSVM(data,labels,kernel,C)\n",
    "        self.svm= svm\n",
    "        density = DriftDetector.findMarginDensity(data,svm)\n",
    "        self.density=density\n",
    "        self.max=density\n",
    "        self.min=density\n",
    "        self.thresh=.075\n",
    "        self.stdDensThresh=2\n",
    "    def setDensThresh(self, newTHresh):\n",
    "        self.stdDensThresh=newTHresh\n",
    "#needs to be adapted for window stuff.\n",
    "    def findMarginDensity(batch,svm):\n",
    "        #vector = svm.support_vectors_[:,0]\n",
    "        start = time.time()\n",
    "        marginDensity=0\n",
    "        for vect in batch:\n",
    "            if np.abs(svm.decision_function([vect]))<=1:\n",
    "                marginDensity= marginDensity+1\n",
    "        end = time.time()\n",
    "        #print(\"findmargindensity\" + str(end-start),flush=True)\n",
    "        return marginDensity/batch.size\n",
    "\n",
    "    def trainSVM(data,labels,kernel,C):\n",
    "        start = time.time()\n",
    "        clf= svm.SVC(kernel=kernel,C=C)\n",
    "        end = time.time()\n",
    "        #print(\"makeSVM\" + str(end-start),flush=True)\n",
    "        start = time.time()\n",
    "        clf.fit(data,labels)\n",
    "        end = time.time()\n",
    "        #print(\"fitsvm\" + str(end-start),flush=True)\n",
    "        return clf\n",
    "#1st version md3\n",
    "    def detectDrift(self,batch):\n",
    "        md2=DriftDetector.findMarginDensity(batch,self.svm)\n",
    "        if md2>self.max:\n",
    "            self.max=md2\n",
    "        if md2<self.min:\n",
    "            self.min= md2\n",
    "        if (self.max-self.min)>self.thresh:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "    #multiclass? linear? etc. retrain once found problem.\n",
    "    def retrain(self,data,labels,kernel,C,K):\n",
    "        self.svm.fit(data,labels)\n",
    "        density = self.findMarginDensity(data)\n",
    "        self.max=density\n",
    "        self.min=density\n",
    "        avAc,stdAc,stdDens= DriftDetector.KXVal(data,labels,kernel,C,K)\n",
    "        self.density=density\n",
    "        self.avAc=avAc\n",
    "        self.stdAc=stdAc\n",
    "        self.stdDens=stdDens\n",
    "##cross avlidaton, gets the distribution components.\n",
    "    def KXVal(data, labels,kernel,C,K):\n",
    "        #print(data)\n",
    "        start = time.time()\n",
    "        splitData=np.array_split(data,K)\n",
    "        np.asarray(splitData)\n",
    "        #print(splitData)\n",
    "        splitLabels=np.array_split(labels,K)\n",
    "        np.asarray(splitLabels)\n",
    "        #print(splitLabels)\n",
    "        accuracies = np.zeros(K)\n",
    "        densities = np.zeros(K)\n",
    "        end = time.time()\n",
    "        #print(\"splitting Data\" +str(end-start),flush=True)\n",
    "        for i in range(K):\n",
    "            #print(splitData[:i])\n",
    "            #print(splitData[i+1])\n",
    "            #concatenate does no check, can't concat an empty array.\n",
    "            start = time.time()\n",
    "            trainData=splitData[:i]+splitData[i+1:]\n",
    "\n",
    "            #print(K)\n",
    "            trainData = np.resize(trainData,(data.shape[0]-splitData[i].shape[0],data.shape[1]))\n",
    "            trainLabels=splitLabels[:i]+splitLabels[i+1:]\n",
    "            #print(trainLabels)\n",
    "            trainLabels= np.resize(trainLabels,(labels.shape[0]-splitLabels[i].shape[0],1))\n",
    "            end = time.time()\n",
    "            #print(\"concat\"+str(end-start),flush=True)\n",
    "            dens,acc= DriftDetector.CrossValid(trainData,splitData[i],trainLabels,splitLabels[i],kernel,C)\n",
    "            accuracies[i]= acc\n",
    "            densities[i] = dens\n",
    "        start = time.time()\n",
    "        averageAccuracy= np.average(accuracies)\n",
    "        standardDevAccuracy= np.std(accuracies)\n",
    "        standardDevDensity=np.std(densities)\n",
    "        #print(averageAccuracy)\n",
    "        #print(\"calcstd Density:\"+ str(standardDevDensity),flush=True)\n",
    "        end = time.time()\n",
    "        #print(\"calcstd,time\"+ str(end-start),flush=True)\n",
    "        return averageAccuracy, standardDevAccuracy,standardDevDensity\n",
    "\n",
    "#this is for batch, not sliding window. sliding window forgetting factor sus\n",
    "#here supposed to query an oracle callback function.\n",
    "    def calculateMD3drift(self,batch):\n",
    "        batchMD= DriftDetector.findMarginDensity(batch,self.svm)\n",
    "        #print(\"this is batch: \" +str(batchMD),flush=True)\n",
    "        #print(\"This is selfDensity: \"+str(self.density), flush= True)\n",
    "        if np.abs(batchMD-self.density)>self.stdDensThresh*self.stdDens:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def checkAccuracy(self,batch,labels):\n",
    "        if batch.size==labels.size:\n",
    "            score=self.svm.score(batch,labels)\n",
    "            if self.avAc-score>self.stdDensThresh*self.stdAc:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "            \n",
    "    # very inefficient, right now, creates new svm. need change the svm, so need to use class svm and fit.\n",
    "    def CrossValid(trainData,testData,trainLabels,testLabels,kernel,C):\n",
    "        start = time.time()\n",
    "        svm= DriftDetector.trainSVM(trainData,trainLabels,kernel,C)\n",
    "        density = DriftDetector.findMarginDensity(trainData,svm)\n",
    "        start = time.time()\n",
    "        score= svm.score(testData,testLabels)\n",
    "        #print(\"this is the score on the dataset: \" + str(score))\n",
    "        end = time.time()\n",
    "        #print(\"calcscore\" + str(end-start),flush=True)\n",
    "        return density, score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #need k cross validation. upgraded\n",
    "    #need the fuzzy algorithm -> basically same algo but using RS and fuzzy. majority voting.\n",
    "    def FeatureSubspace(data, labels,kernel,C,K):\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def randomSubspace(data):\n",
    "        \n",
    "        pass\n",
    "    ##need virtual margins implementation. inda dumb, just about confidence levels?\n",
    "    ##ask lorena: if the same but with different way to find classification, not ... if using window.\n",
    "    #non lineear margins... vrtual.\n",
    "    \n",
    "dd= DriftDetector(X,Y,\"linear\",1,2)\n",
    "if dd.calculateMD3drift(X):\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing.\n",
    "#LabelEncoder\n",
    "#iloc and sclice...\n",
    "#functions to help make arf to usable data\n",
    "def getCatColumns(pandaFrame):\n",
    "    names = pandaFrame.select_dtypes(exclude=np.number).columns.tolist()\n",
    "    return names\n",
    "    \n",
    "\n",
    "def fromArftoData(link):\n",
    "    #load data\n",
    "    data = arff.loadarff(link)[0]\n",
    "    df= pd.DataFrame(data)\n",
    "    #encode labels\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels= le.fit_transform(df[['class']])\n",
    "    print(\"preprocessed\",flush=True)\n",
    "    #encode categorical\n",
    "    columns = getCatColumns(df)\n",
    "    print(\"getcolumns\",flush=True)\n",
    "    ord= preprocessing.OrdinalEncoder()\n",
    "    scaler= MinMaxScaler()\n",
    "    df[columns[:]]=ord.fit_transform(df[columns[:]])\n",
    "    print(\"get the preprocessed things\",flush=True)\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    trainingData = df.iloc[:,:-1]\n",
    "    numpData=trainingData.to_numpy()\n",
    "    print(\"tonumpy.\",flush=True)\n",
    "    return numpData,labels\n",
    "\n",
    "# link = \"agraw1_1_abrupt_drift_0_noise_balanced.arff\"\n",
    "# data,labels = fromArftoData(\"agraw1_1_abrupt_drift_0_noise_balanced.arff\")\n",
    "# drifDet= DriftDetector(data[:30000],labels[:30000],\"linear\",1,10)\n",
    "#print(data)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed\n",
      "getcolumns\n",
      "get the preprocessed things\n",
      "tonumpy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average accuracy of this model:0.8347333333333333\n",
      "Source:sea_1_abrupt_drift_0_noise_balanced.arff\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "preprocessed\n",
      "getcolumns\n",
      "get the preprocessed things\n",
      "tonumpy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average accuracy of this model:0.9143000000000001\n",
      "Source:agraw1_1_abrupt_drift_0_noise_balanced.arff\n",
      "no\n",
      "no\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "preprocessed\n",
      "getcolumns\n",
      "get the preprocessed things\n",
      "tonumpy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "c:\\Python38\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average accuracy of this model:0.8807333333333334\n",
      "Source:agraw2_1_abrupt_drift_0_noise_balanced.arff\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'synthetic_data\\\\gradual_drift\\x07graw1_1_gradual_drift_0_noise_balanced_1.arff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m theSources\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m\"\u001b[39m\u001b[39msea_1_abrupt_drift_0_noise_balanced.arff\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39magraw1_1_abrupt_drift_0_noise_balanced.arff\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m ,\u001b[39m\"\u001b[39m\u001b[39magraw2_1_abrupt_drift_0_noise_balanced.arff\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\u001b[39m\u001b[39msynthetic_data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mgradual_drift\u001b[39m\u001b[39m\\a\u001b[39;00m\u001b[39mgraw1_1_gradual_drift_0_noise_balanced_1.arff\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m\"\u001b[39m\u001b[39msynthetic_data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mgradual_drift\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msea_1_gradual_drift_0_noise_balanced_10.arff\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m \u001b[39m\"\u001b[39m\u001b[39msynthetic_data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mgradual_drift\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msea_1_gradual_drift_0_noise_balanced_20.arff\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,theSources\u001b[39m.\u001b[39msize):\n\u001b[1;32m---> 19\u001b[0m     data,labels \u001b[39m=\u001b[39m fromArftoData(theSources[ind])\n\u001b[0;32m     20\u001b[0m     \u001b[39m#print(data)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     drifDet\u001b[39m=\u001b[39m DriftDetector(data[:\u001b[39m30000\u001b[39m],labels[:\u001b[39m30000\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39mpoly\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn [3], line 12\u001b[0m, in \u001b[0;36mfromArftoData\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromArftoData\u001b[39m(link):\n\u001b[0;32m     11\u001b[0m     \u001b[39m#load data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     data \u001b[39m=\u001b[39m arff\u001b[39m.\u001b[39;49mloadarff(link)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m     df\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n\u001b[0;32m     14\u001b[0m     \u001b[39m#encode labels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\scipy\\io\\arff\\_arffread.py:800\u001b[0m, in \u001b[0;36mloadarff\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    798\u001b[0m     ofile \u001b[39m=\u001b[39m f\n\u001b[0;32m    799\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 800\u001b[0m     ofile \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(f, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    802\u001b[0m     \u001b[39mreturn\u001b[39;00m _loadarff(ofile)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'synthetic_data\\\\gradual_drift\\x07graw1_1_gradual_drift_0_noise_balanced_1.arff'"
     ]
    }
   ],
   "source": [
    "\n",
    "theSources= np.array([\"sea_1_abrupt_drift_0_noise_balanced.arff\",\"agraw1_1_abrupt_drift_0_noise_balanced.arff\"\n",
    ",\"agraw2_1_abrupt_drift_0_noise_balanced.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "\"agraw1_1_gradual_drift_0_noise_balanced_20.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "\"agraw2_1_gradual_drift_0_noise_balanced_20.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_1.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_5.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_05.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_10.arff\",\n",
    "\"sea_1_gradual_drift_0_noise_balanced_20.arff\"])\n",
    "for ind in range(0,theSources.size):\n",
    "    data,labels = fromArftoData(theSources[ind])\n",
    "    #print(data)\n",
    "    drifDet= DriftDetector(data[:30000],labels[:30000],\"poly\",1,5)\n",
    "    print(\"This is the average accuracy of this model:\"+str(drifDet.avAc),flush=True)\n",
    "    batches = np.array_split(data,10)\n",
    "    batches = np.asarray(batches)\n",
    "    print(\"Source:\" + theSources[ind])\n",
    "    for i in range(3,batches.shape[0]):\n",
    "        if drifDet.calculateMD3drift(batches[i]):\n",
    "            print(\"yes\")\n",
    "        else:\n",
    "            print(\"no\")\n",
    "\n",
    "\n",
    "# for ind in range(theSources.size):\n",
    "#     print(\"Source:\" + theSources[ind])\n",
    "#     for i in range(3,batches.shape[0]):\n",
    "#         if drifDet.detectDrift(batches[i]):\n",
    "#             print(\"yes\")\n",
    "#         else:\n",
    "#             print(\"no\")\n",
    "\n",
    "##to change perhaps: expected density etc.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
